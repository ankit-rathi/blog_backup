<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://ankit-rathi.github.io/data-and-ai/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ankit-rathi.github.io/data-and-ai/" rel="alternate" type="text/html" /><updated>2020-04-30T04:12:00-05:00</updated><id>https://ankit-rathi.github.io/data-and-ai/feed.xml</id><title type="html">Data &amp;amp; AI Blog</title><subtitle>From Data To Actionable Insights</subtitle><entry><title type="html">From Data To Actionable Insights</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/30/From-Data-To-Actionable-Insights.html" rel="alternate" type="text/html" title="From Data To Actionable Insights" /><published>2020-04-30T00:00:00-05:00</published><updated>2020-04-30T00:00:00-05:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/30/From-Data-To-Actionable-Insights</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/30/From-Data-To-Actionable-Insights.html">&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/2000/1*vJu3xpSgK6X0T_jfUnh5_A.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
  &lt;h2 id=&quot;data-is-the-new-oil-ai-is-the-new-electricity&quot;&gt;Data is the new oil, AI is the new electricity.&lt;/h2&gt;
&lt;/blockquote&gt;

&lt;p&gt;You may keep hearing these terms of late. As Data &amp;amp; AI field is gaining immense traction, every organization or business is looking to make the most of the opportunities available to them.&lt;/p&gt;

&lt;p&gt;Many of you may be working on relevant projects as well, where you collect, store, process, analyse data, and serve the insights to business stakeholders. Some of you may be using the latest ML/AI techniques in your projects and may be aware of CRISP-DM technique.&lt;/p&gt;

&lt;p&gt;If you are working on a one-off project in the AI/ML area, it is fine to just get the work done but if you have many use-cases, it makes sense to have a streamlined approach, for data ingestion, storage, processing and service, so that common resources (data, pipelines, infra etc) can be used across use cases. That’s where design, architecture &amp;amp; governance come into the picture.&lt;/p&gt;

&lt;p&gt;In this article, I would like to show you the typical design of data-intensive applications using a data platform.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Data &amp;amp; AI being a vast field having many sub-fields, a single post is not enough to explain each component to sufficient depth, so I will cover the in-depth view of each component/function in upcoming posts.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;data--actionable-insights&quot;&gt;Data &amp;amp; Actionable Insights&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*T1WfVLbR0uwfNzBEhQBmtw.png&quot; alt=&quot;&quot; /&gt;
On the highest level of abstraction, you can see a data &amp;amp; AI system as a black box, where data goes in and actionable insights come out. Let’s look at what’s there in this black-box.&lt;/p&gt;

&lt;h2 id=&quot;core--support-functions&quot;&gt;Core &amp;amp; Support Functions&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*AX1iXOcu0SFMKPVd21rvLA.png&quot; alt=&quot;&quot; /&gt;
If you look into this black-box, you can see that there are some core functions and some support functions to transform data into actionable insights. Core functions work on data while support functions manage and optimize core functions.&lt;/p&gt;

&lt;h2 id=&quot;understanding-the-big-picture&quot;&gt;Understanding the Big Picture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*yqeLNbPxe1BlrQk-z0__Iw.png&quot; alt=&quot;&quot; /&gt;
In a typical data analytics platform, there are four core functions and three support functions. Core functions provide functional requirements while support functions facilitate the non-functional requirements.&lt;/p&gt;

&lt;p&gt;As part of core functions, data is ingested, stored, processed, analysed and served to business stakeholders to fulfil Data &amp;amp; AI use cases.&lt;/p&gt;

&lt;p&gt;Support functions take care of infrastructure, security, performance, scalability and delivery aspects of these use cases.&lt;/p&gt;

&lt;p&gt;Let’s have a look at each one of them:&lt;/p&gt;

&lt;h2 id=&quot;data-ingestion&quot;&gt;Data Ingestion&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*CrN_yrcBei0le6t_4mHf2g.png&quot; alt=&quot;&quot; /&gt;
Data Ingestion deals with all the challenges related to incoming data. Its a framework that makes it easier to collect and integrate data from different types of data sources and support different types of data transport protocols.&lt;/p&gt;

&lt;p&gt;Some of the challenges faced here are: multiple source ingestion, managing streaming/real-time data, speed of ingestion, change detection.&lt;/p&gt;

&lt;h2 id=&quot;data-storage&quot;&gt;Data Storage&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*DQF7xxPaLroHsoCCahxHWw.png&quot; alt=&quot;&quot; /&gt;
Once you have ingested data into your platform, you need to store it somewhere. There are different types of storages/databases and we select specific storages/databases keeping various factors in mind like data type, ingestion type, processing and request types.&lt;/p&gt;

&lt;p&gt;Notable storage types used in typical data platforms are file storage, Databases, Data Warehouses, Data Lakes, Delta Lakes, Data Mesh etc.&lt;/p&gt;

&lt;h2 id=&quot;data-processing--analysis&quot;&gt;Data Processing &amp;amp; Analysis&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*qVM7MkscynGujkc0Z0opGQ.png&quot; alt=&quot;&quot; /&gt;
To draw insights from data, we may need to clean, impute, analyse, transform, aggregate it. We may need to build meaningful features in order to build useful models. All these activities are taken care of in this function.&lt;/p&gt;

&lt;p&gt;Data engineering, Big Data processing, Business Intelligence, Machine Learning and Artificial Intelligence capabilities are applied to the data as part of this function.&lt;/p&gt;

&lt;p&gt;Apart from raw data, we may need to store intermediate data or derived insights in order to consume it later. Hence processing, analysis and storage functions may be used iteratively.&lt;/p&gt;

&lt;h2 id=&quot;data-service&quot;&gt;Data Service&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*qVM7MkscynGujkc0Z0opGQ.png&quot; alt=&quot;&quot; /&gt;
Actionable insights have to be consumed by business stakeholders and customers. Data service function takes care of hosting these insights. The type of data service can be APIs, KPI reports/dashboards, notebooks and development environments.&lt;/p&gt;

&lt;h2 id=&quot;cloud-services&quot;&gt;Cloud Services&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*2fGS-Ja0FBLpZkOMS9RbOA.png&quot; alt=&quot;&quot; /&gt;
All the above functions (as well as DevOps &amp;amp; Governance functions) can be built on-premise as well as on-cloud. Due to various benefits in terms of infrastructure, platform &amp;amp; application, the cloud has become go to support function for almost all the technology requirements.&lt;/p&gt;

&lt;p&gt;Type of cloud services is available as follows: IaaS, PaaS &amp;amp; SaaS. Major cloud providers in Data &amp;amp; AI area are AWS, Azure &amp;amp; GCP. We will learn more about these terms in upcoming posts.&lt;/p&gt;

&lt;h2 id=&quot;devops&quot;&gt;DevOps&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*2fGS-Ja0FBLpZkOMS9RbOA.png&quot; alt=&quot;&quot; /&gt;
The term DevOps is a combination of two words namely Development and Operations. DevOps is a function that allows a single team to manage the entire application development life cycle, that is, development, testing, deployment, and monitoring.&lt;/p&gt;

&lt;p&gt;The ultimate goal of DevOps is to decrease the duration of the system’s development life cycle while delivering features, fixes, and updates frequently in close synchronization with business objectives.&lt;/p&gt;

&lt;p&gt;It consists of various stages such as continuous development, continuous integration, continuous testing, continuous deployment, and continuous monitoring.&lt;/p&gt;

&lt;p&gt;Notable tools in DevOps area are Git, Jenkins, Kubernetes, Chef, Nagios etc.&lt;/p&gt;

&lt;h2 id=&quot;governance&quot;&gt;Governance&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*2fGS-Ja0FBLpZkOMS9RbOA.png&quot; alt=&quot;&quot; /&gt;
Data governance is a function to manage the availability, usability, integrity and security of the data in enterprise systems, based on internal data standards and policies that also control data usage. Effective data governance ensures that data is consistent and trustworthy and doesn’t get misused.&lt;/p&gt;

&lt;p&gt;This function also includes other concepts such as Data Stewardship, Data Quality, and others to help an enterprise gain better control over its data assets, including methods, technologies, and behaviours around the proper management of data.&lt;/p&gt;

&lt;h2 id=&quot;putting-it-all-together&quot;&gt;Putting It All Together&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1400/1*vR8dBkIDd_E6OvISB4vFNw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So this post, though it was a high-level view, we learnt about how actionable insights are generated from data. I believe you found this post helpful, we will dive deeper into the above components/functions in upcoming posts.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://www.youtube.com/channel/UCrIv4EU2tFX8VhhT0oCnDnw&quot;&gt;&lt;em&gt;YouTube&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">AI Sells, Data Delivers!</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/25/AI-Sells-Data-Delivers.html" rel="alternate" type="text/html" title="AI Sells, Data Delivers!" /><published>2020-04-25T00:00:00-05:00</published><updated>2020-04-25T00:00:00-05:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/25/AI-Sells-Data-Delivers</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/25/AI-Sells-Data-Delivers.html">&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*oneAF1ru_QWnIb775r0wmw.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;context&quot;&gt;Context&lt;/h2&gt;
&lt;p&gt;The world has advanced at a faster pace and new technologies are reshaping the business world and society. One of these emerging technologies, Artificial Intelligence (AI), has gained immense momentum in the world like other technologies such as the IoT, Blockchain, 3D printing, Robotics etc.&lt;/p&gt;

&lt;p&gt;AI is all around us these days, both in areas that border on science fiction, like self-driving cars to the more ordinary tasks like what show should you watch or purchase next. AI is influencing almost every walk of life, from businesses to society. With these technologies, the business will gain more agility needed to solve problems that humans can’t possibly solve.&lt;/p&gt;

&lt;h2 id=&quot;three-components-ofai&quot;&gt;Three Components of AI&lt;/h2&gt;
&lt;p&gt;Apart from the context of the domain where AI is being applied, there are three main components of AI:
&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*nqj3UWtlGvTq8oy2m0c10w.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The first one is the AI algorithm itself. Open-source machine learning libraries like Keras, Theano and TensorFlow have shed a lot of the low-level complexity involved in designing and building AI applications. These tools are free, well documented and supported by vibrant communities. The availability of these tools has made building AI applications far more accessible to developers.&lt;/p&gt;

&lt;p&gt;The second one is computing power, both in the form of raw CPU power and large scale data storage solutions. Cloud services like Amazon Web Services, Google Cloud, Microsoft Azure and others make renting servers, virtual machines and big data tools are as simple as pushing a few buttons.&lt;/p&gt;

&lt;p&gt;The third but the most important one is data. Before you can contemplate hiring data scientists, renting or paying for servers and installing open-source machine learning libraries, you must have data. The quality and depth of data will determine the level of AI applications you can achieve.&lt;/p&gt;

&lt;h2 id=&quot;data-ai&quot;&gt;Data &amp;amp; AI&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*OyUtvGybX6HYZGWHy4DvaA.png&quot; alt=&quot;&quot; /&gt;
Source: https://www.ibm.com/cloud/garage/architectures/dataAnalyticsArchitecture&lt;/p&gt;

&lt;p&gt;While AI is a reasonably wide area of study in computer science, most of the excitement these days is centred on an area of AI called machine learning and in particular, deep learning. Machine learning trains the algorithms to learn and predict answers to problems by analysing data to make predictions on their own.&lt;/p&gt;

&lt;p&gt;As we discussed above, the promise of AI depends on certain ingredients for successful adoption; one of the critical ingredients for a successful AI implementation is a clean, representative and large amount of historical data. However, unless you are Google or Facebook with vast amounts of representative data, you will struggle to harvest historical data that are enough to give the required inference for machine learning techniques to be an effective enabler for AI initiatives. Therefore, to make AI work, there is a need for an improved level of data preparation, engineering, enrichment, and contextualization.&lt;/p&gt;

&lt;p&gt;As with most reports about groundbreaking technology, this discussion is way ahead of current industry practices. The vision serves a useful purpose in suggesting what’s possible. But with many businesses lacking the data infrastructure necessary to obtain real AI and ML capabilities, the journey towards perfect production can also be so abstract that it perplexes the very people looking to achieve it.&lt;/p&gt;

&lt;p&gt;AI algorithms learn from data. It is critical that you feed them the right data for the problem you want to solve. Even if you have good data, you need to make sure that it is on a useful scale, format and even that meaningful features are included. Understand the key capabilities you need for collaborative, operational data preparation pipelines to serve the needs of both your data and business analysts.&lt;/p&gt;

&lt;p&gt;During the global launch of the Outside Insight book, author and Meltwater CEO Jorn Lyseggen, alongside AI experts, discussed the importance of the data fueling AI, and the need for executives using AI outputs for decision-making to both understand the data informing those outputs and ensure it’s as comprehensive and unbiased as possible.&lt;/p&gt;

&lt;p&gt;“Artificial Intelligence is your rocket, but data is the fuel. You can have the best algorithms in the world, an amazing rocket, but you’re only going to get as far as your data gets you. Data is fundamental - data is AI,” said Gerardo Salandra, Chairman of the AI Society of Hong Kong and CEO at Rocketbots, at the Hong Kong launch event.&lt;/p&gt;

&lt;p&gt;Similarly, Monica Rogati’s Data Science Hierarchy of Needs is a pyramid showing what’s necessary to add intelligence to the production system. At the bottom is the need to gather the right data, in the right formats and systems, and in the right quantity. Any application of AI and ML will only be as good as the quality of data collected.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/0*gMTiDUjK4OFz2KHA.jpg&quot; alt=&quot;&quot; /&gt;
Source: https://hackernoon.com/the-ai-hierarchy-of-needs-18f111fcc007&lt;/p&gt;

&lt;p&gt;In the growing AI market, International Data Corporation (IDC) predicts global spending is expected to increase 50% per year, to a total of $57.6 billion by 2021. Business leaders are catching on to the importance of implementing an AI strategy globally. However, it’s not enough just to introduce AI-driven tools; you need the right data inputs to find valuable insights.&lt;/p&gt;

&lt;h2 id=&quot;importance-ofdata&quot;&gt;Importance of Data&lt;/h2&gt;
&lt;p&gt;A lot has been written about AI recently, but one element that is often not stressed is the value data plays in allowing AI to function. Take self-driving cars - probably the most recognized application of AI. Building a self-driving car requires a humongous amount of data ranging from signals from infrared sensors, images from digital cameras, and high-resolution maps. NVIDIA estimates that one self-driving car generates 1 TB per hour of raw data. All that data is then used in the development of the AI models that actually drive the car.&lt;/p&gt;

&lt;p&gt;While we have seen recent advances in other AI techniques like reinforcement learning that use less data (like the success of Deep Mind’s recent Alpha Go - Zero in the game of GO), data is still critical for developing AI applications.&lt;/p&gt;

&lt;p&gt;Enterprises are overwhelmed with silo IT systems built over the years that contain data designed to do very specific individual ‘System of Record’ tasks, but unfortunately, these records are duplicated across multiple ‘Systems of Record’ resulting in massive data proliferation but lacking complete representation of an entity in any single system. This reality has given rise to fragmented and often duplicated data landscape that requires expensive and often non-efficient means of establishing ‘Source of Truth’ data sets.&lt;/p&gt;

&lt;h2 id=&quot;data-provides-intelligence-toai&quot;&gt;Data provides ‘Intelligence’ to AI&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*KnXVRW53ATJeiTMbVAG4QA.png&quot; alt=&quot;&quot; /&gt;
AI applications improve as they gain more experience (means more data) but present AI applications have an unhealthy infatuation with gaining this experience exclusively from Machine Learning techniques. While there is nothing inherently wrong with Machine Learning, the main caveat for a successful Machine Learning outcome is sufficient and representative historical data for the machine to learn from. For example, if an AI model is learning to recognize chairs and has only seen standard dining chairs that have four legs, the model may believe that chairs are only defined by four legs. This means if the model is shown to, say, a desk chair that has one pillar, it will not recognize it as a chair.&lt;/p&gt;

&lt;h2 id=&quot;preparing-data-forai&quot;&gt;Preparing data for AI&lt;/h2&gt;
&lt;p&gt;While your organisation may not be at the stage where you are able to start building AI applications, at the least you should be preparing for a future where your data will be utilised to power smart solutions. Treat every new initiative or project as an opportunity to build a foundation for future data models.&lt;/p&gt;

&lt;h3 id=&quot;data-collection&quot;&gt;Data Collection&lt;/h3&gt;
&lt;p&gt;This aspect has become crucial in light of the GDPR legislation. Are there clear and followed guidelines about what and why data is collected when a new feature or product is being developed? Does that data have a purpose or is it being collected just like that?&lt;/p&gt;

&lt;h3 id=&quot;data-format&quot;&gt;Data Format&lt;/h3&gt;
&lt;p&gt;When you are collecting data, is it being saved in a usable format across all our data collection touchpoints? Are the field names the same? Is the same level of validation and error checking applied across products?&lt;/p&gt;

&lt;h3 id=&quot;data-storage&quot;&gt;Data Storage&lt;/h3&gt;
&lt;p&gt;Data needs to be flowing into data stores and be available in real-time to all areas of the business. Given that AI applications usually become more reliable the more they can correlate different sources of information, siloed data sets that are hard to access become an obstacle to discovering value in an organisation’s data.&lt;/p&gt;

&lt;h3 id=&quot;data-literacy&quot;&gt;Data Literacy&lt;/h3&gt;
&lt;p&gt;AI is basically biased in how it was created, trained, programmed. One of the most significant things for AI to be successful is that executives and decision-makers have the data literacy to beat up the model, to challenge the model, to massage the model and to fully understand what the underlying assumptions are to make sure the answer it produces actually matches the terrain that you want to operate in. What’s vital to get the best predictive models and forward-looking insights is that the data informing them comes from a variety of external sources.&lt;/p&gt;

&lt;h3 id=&quot;more-data&quot;&gt;More Data&lt;/h3&gt;
&lt;p&gt;Just like humans, AI applications improve with more experience. Data provides examples essential to train models that can perform predictions and classifications. A good example of this is in image recognition. The availability of data through ImageNet transformed the pace of change in image understanding and led to computers reaching human-level performance. A general rule of thumb is that you need 10 times as much data as the number of parameters (i.e., degrees of freedom) in the model being built. The more complicated the task, the more data needed.&lt;/p&gt;

&lt;h3 id=&quot;data-understanding&quot;&gt;Data Understanding&lt;/h3&gt;
&lt;p&gt;For cooking the perfect meal, it’s great to know the tastes of your diners. Similarly, data is essential to tailoring an AI model to the wants of specific users. We need to learn how users use their applications and search content in order to generate meaningful personalized recommendations.&lt;/p&gt;

&lt;p&gt;By knowing what content users read, download and collect, we can give them advice on potential content of interest. Furthermore, techniques such as collaborative filtering, which make suggestions based on the similarity between users, improve with access to more data; the more user data one has, the more likely it is that the algorithm can find a similar a user.&lt;/p&gt;

&lt;h3 id=&quot;diverse-data&quot;&gt;Diverse Data&lt;/h3&gt;
&lt;p&gt;A key problem in building AI models is overfitting - this is, where the model focuses too specifically on the examples given. For instance, if a model is trying to learn to recognize chairs and has only been shown standard dining chairs with four legs, it may learn that chairs are defined by having four legs. If the model is then shown a desk chair with just one pillar, it wouldn’t recognize it. Having diverse data helps combat this problem.&lt;/p&gt;

&lt;p&gt;During training, the AI model can view more examples of different types of things. This is particularly valuable in working with data about people, where there can be the potential for algorithmic bias against people from diverse backgrounds. This point was made by Prof. Dame Wendy Hall in her interview at the World Summit AI. Prof. Hall focused on the need to make sure that AI was trained on diverse datasets. A good example of combating this through data is the lengths that Apple went to in training their new Face ID recognition algorithm.&lt;/p&gt;

&lt;h3 id=&quot;external-data&quot;&gt;External Data&lt;/h3&gt;
&lt;p&gt;As the race to implement AI tools at an enterprise-level reaches new heights, it’s important to note that the data informing those tools is of paramount importance. Relying only on internal information to inform algorithms will produce insights gleaned only from the information you already have. Rather, it’s vital that decision-makers also look to insights from external data for a much more comprehensive and unbiased view of their customers and industry landscape.&lt;/p&gt;

&lt;h3 id=&quot;hypothesis-testing&quot;&gt;Hypothesis Testing&lt;/h3&gt;
&lt;p&gt;Even in cases where techniques can be used that require less training data, more data makes it easier to test AI systems. An example of this is A/B testing. This is where a developer takes a small amount of traffic to a site and tests to see whether a new recommendation engine or search algorithm performs better on that small set of traffic.&lt;/p&gt;

&lt;p&gt;The more traffic (means data), the easier it is to test multiple algorithms or variants. At the World AI Summit, Netflix explained how they use A/B testing to select artwork that maximizes the engagement with films and TV series on Netflix.&lt;/p&gt;

&lt;h3 id=&quot;data-reusability&quot;&gt;Data Reusability&lt;/h3&gt;
&lt;p&gt;Finally, it is usually the case that data can be reused for different applications. For example, a technique called transfer learning allows data developed for one domain to be applied to another domain. Moreover, recent work has revealed that background knowledge can further improve on tasks like object detection in images. Recent work from Google has shown how training using data designated for a different task like image recognition can help performance on another completely different task like language translation.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In summary, data is the pivotal element in developing any AI system today.&lt;/p&gt;

&lt;p&gt;In the near future, what we are now calling AI will be embedded in our culture and we won’t call it AI any longer. It will just be how things work. What you have in your control today is your data. It’s crucial that you start preparing for a future where AI applications can start using your data and that starts with the quantity and quality of the data itself.&lt;/p&gt;

&lt;p&gt;Embracing AI with business &amp;amp; society is a journey, not a silver bullet that will solve challenges instantly. It begins with gathering data into simple visualizations and statistical processes that allow you to better understand your data and get your processes under control. From there, you’ll progress through increasingly advanced analytical capabilities, until you achieve that utopian aim of perfect production, where you have AI helping you make products as efficiently and reliably as possible.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://www.youtube.com/channel/UCrIv4EU2tFX8VhhT0oCnDnw&quot;&gt;&lt;em&gt;YouTube&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Data &amp;amp; AI Platforms — Open Source Vs Managed Services</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/20/Data-AI-Platforms-Open-Source-Vs-Managed-Services.html" rel="alternate" type="text/html" title="Data &amp; AI Platforms — Open Source Vs Managed Services" /><published>2020-04-20T00:00:00-05:00</published><updated>2020-04-20T00:00:00-05:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/20/Data-AI-Platforms-Open-Source-Vs-Managed-Services</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/20/Data-AI-Platforms-Open-Source-Vs-Managed-Services.html">&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1500/1*Svz8nTTFVj8OAdZMhrCiiQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;While designing and building Data &amp;amp; AI platforms, you may need to evaluate the options available. Whether your platform would be on-premise or you could use cloud/s services or you would take a hybrid approach.
In any case, you may need to look and evaluate various tools &amp;amp; services for your ingestion, storage, process/analysis and serving layers.
In this post, I have mapped open-source and popular managed cloud services to make our evaluation process a bit easier.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1500/1*-lxchArCT3aAPsBWjS-cBQ.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://cdn-images-1.medium.com/max/1500/1*0wyyPh2jLjFs9-e5YRE4UA.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://cdn-images-1.medium.com/max/1500/1*29JnAqIQuw58X1OCYGPROg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I will be comparing these services with their pros and cons and when to use which service in upcoming posts, stay tuned.
I hope you find this post useful, stay tuned for more, any feedback would be highly appreciated.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://www.youtube.com/channel/UCrIv4EU2tFX8VhhT0oCnDnw&quot;&gt;&lt;em&gt;YouTube&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Architecting Modern Data Platforms</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/15/Architecting-Modern-Data-Platforms.html" rel="alternate" type="text/html" title="Architecting Modern Data Platforms" /><published>2020-04-15T00:00:00-05:00</published><updated>2020-04-15T00:00:00-05:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/15/Architecting-Modern-Data-Platforms</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2020/04/15/Architecting-Modern-Data-Platforms.html">&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1500/1*XY87VHW3-cJGMb7XNfUZRQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;data-architecture-principles&quot;&gt;Data Architecture Principles&lt;/h2&gt;

&lt;p&gt;Whether you are responsible for data, systems or application architecture, you need to define some principles to help you navigate the fast-paced modern world. Data Architecture Principles are the foundation for data architecture that will allow your business to run at an optimized level today, and into the future.&lt;/p&gt;

&lt;h3 id=&quot;adhere-to-adda-accessibility-definition-decoupling-agility&quot;&gt;Adhere to ADDA (Accessibility, Definition, Decoupling, Agility)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*nUhGoJeLJvDz8B8mcAlgig.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Data Accessibility is critical for the success of any business. Easily accessible data enables you to move quickly, focus on the product, and build a data-informed pipeline where data leads to better decisions and actions.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Data Definition or Catalog helps analysts and other data users to find the data that they need, serves as an inventory of available data, and provides information to evaluate fitness data for intended uses.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Data Decoupling helps in design since it allows each data layer to be independent of other data layers.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Data Agility is when your data can move at the speed of your business. For companies to achieve true data agility, they need to be able to access the data they need, when and where they need it.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So the first data architecture principle is to make sure that business data is accessible, defined, decoupled and agile.&lt;/p&gt;

&lt;h3 id=&quot;design-for-rsm-reliability-scalability-maintainability&quot;&gt;Design for RSM (Reliability, Scalability, Maintainability)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*B5TsIF4HDMEo_JRuMHOhWw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reliability means the data systems we are designing work correctly and fault-tolerant up to some level.&lt;/li&gt;
  &lt;li&gt;Scalability means data systems are adaptable to growth in a linear way.&lt;/li&gt;
  &lt;li&gt;Maintainability means that data systems remain easier to maintain.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Second data architecture principle is that the data systems remain reliable, scalable and maintainable over time.&lt;/p&gt;

&lt;h3 id=&quot;use-right-tools&quot;&gt;Use Right Tools&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*lfW4KerKIMivkID8Cc9noA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We need to use the right tool at each data layer by aligning the choice to the data structure, latency and throughput requirements and access patterns.&lt;/p&gt;

&lt;h3 id=&quot;cloud-nativeagnostic&quot;&gt;Cloud-Native/Agnostic&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*_I3Ge-AIWtFBvyH7_21IUw.png&quot; alt=&quot;&quot; /&gt;
Whether you have the data on-premise or you are using single/multiple cloud service providers, each decision has its own pros &amp;amp; cons.&lt;/p&gt;

&lt;h3 id=&quot;be-cost-conscious&quot;&gt;Be Cost-Conscious&lt;/h3&gt;
&lt;p&gt;Cost of building complex and ever-evolving data systems can be huge, we need to make sure we use available resources efficiently.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Efficient consumption of services&lt;/li&gt;
  &lt;li&gt;Select cost-conscious options&lt;/li&gt;
  &lt;li&gt;Enforce policies and controls&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-lake-basics&quot;&gt;Data Lake Basics&lt;/h2&gt;
&lt;p&gt;Data Lake is becoming the defacto standard in modern data platforms, let’s have a look at what it is and how it helps to build modern data systems.&lt;/p&gt;

&lt;h3 id=&quot;data-lake-definition&quot;&gt;Data Lake Definition&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;An architectural approach&lt;/li&gt;
  &lt;li&gt;Massive heterogeneous data stored centrally&lt;/li&gt;
  &lt;li&gt;Available to the diverse group of users&lt;/li&gt;
  &lt;li&gt;To be categorized, processed, analyzed &amp;amp; consumed&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;data-lake-characteristics&quot;&gt;Data Lake Characteristics&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Structured, semi-structured &amp;amp; unstructured data&lt;/li&gt;
  &lt;li&gt;Scaled out as required&lt;/li&gt;
  &lt;li&gt;The diverse set of storage, analytics and ML/AI tools&lt;/li&gt;
  &lt;li&gt;Designed for low-cost storage and analytics&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;high-level-architecture&quot;&gt;High-Level Architecture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*ydcHHJxlQZJc7bRsFEy-qw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A typical data analytics platform takes business raw data as input and provides actionable insights. It has four layers: ingest, store, process/analyse &amp;amp; serve.
Let’s have a look at each data layer in detail:&lt;/p&gt;

&lt;h2 id=&quot;data-characteristics&quot;&gt;Data Characteristics&lt;/h2&gt;

&lt;h3 id=&quot;ingest&quot;&gt;Ingest&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Data can be ingested from a variety of data sources like web/mobile apps, databases, application logging, messaging and IOT devices.
&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*gqnD79N34Epji2EZklZ0eg.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;Data can be hot, warm or cold based on its velocity, request rates and latency requirements:
&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*xMOM4kkrQZ4WosF9x0kwXQ.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;Data can be categorized based on data structures and access-pattern requirements. Based on these characteristics, we decide how to store and process each type of data.
&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*rPI43SQbQCvb6H70PeId8A.png&quot; alt=&quot;&quot; /&gt;
    &lt;h3 id=&quot;storage&quot;&gt;Storage&lt;/h3&gt;
  &lt;/li&gt;
  &lt;li&gt;How we are going to store data depends mainly on two major factors:&lt;/li&gt;
  &lt;li&gt;What is the structure of the data?&lt;/li&gt;
  &lt;li&gt;What is the frequency and usage of data?
&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*AKhZoJXjcb5ue9rfgWXe3Q.png&quot; alt=&quot;&quot; /&gt;
    &lt;h3 id=&quot;analytics-types&quot;&gt;Analytics Types&lt;/h3&gt;
    &lt;p&gt;There can be different kind of analytics you may need to perform based on the structure and access-patterns of data.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Message/Stream Analysis&lt;/li&gt;
  &lt;li&gt;Interactive Analysis&lt;/li&gt;
  &lt;li&gt;Batch Analysis&lt;/li&gt;
  &lt;li&gt;Machine Learning/AI&lt;/li&gt;
  &lt;li&gt;ETL Processing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Store and Process/Analyse steps can be performed iteratively as after processing or analysing the results, you may need to store data in the processed form before acting further.
&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*zRYSvV-JLCwG3rIf6etUdg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;serve&quot;&gt;Serve&lt;/h3&gt;
&lt;p&gt;There may be various ways of serving insights to end-user (business, data scientists or developers).&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Applications &amp;amp; APIs&lt;/li&gt;
  &lt;li&gt;Analysis &amp;amp; Visualization&lt;/li&gt;
  &lt;li&gt;Notebooks&lt;/li&gt;
  &lt;li&gt;IDEs&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;putting-it-all-together&quot;&gt;Putting It All Together&lt;/h2&gt;
&lt;p&gt;Now let’s combine what we have discussed till now, you may notice that ‘Security and Governance’ process needs to be applied across the data layers along with Data Catalog.
&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*-H4qKZwKOxYHtIgyRLh8fw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;product-driven-data-architecture&quot;&gt;Product-Driven Data Architecture&lt;/h2&gt;
&lt;p&gt;While data lake is the defacto standard these days, still there are few issues that are to be addressed like ubiquitous data and source proliferation, innovation agenda and consumer proliferation, coupled pipeline decomposition.
Recently, Zhamak Dehghani has proposed a data architecture to move beyond a monolithic data lake to a distributed data mesh which can possibly address above mentioned concerns.
&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*GOP7DOIVIOZ_oBVnRksWbg.png&quot; alt=&quot;&quot; /&gt;
https://martinfowler.com/articles/data-monolith-to-mesh.html&lt;/p&gt;

&lt;h2 id=&quot;reference-architecture&quot;&gt;Reference Architecture&lt;/h2&gt;
&lt;p&gt;Before signing off, let’s also have a look at reference data architecture from leading cloud services providers like Azure, AWS and GCP.&lt;/p&gt;

&lt;h3 id=&quot;reference-architecture--azure&quot;&gt;Reference Architecture — Azure&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*SZ896yzUQfJlYuclLUf8Ow.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;reference-architecture--aws&quot;&gt;Reference Architecture — AWS&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*sMSQEc9_L8wm2DpxzsknEg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;reference-architecture--gcp&quot;&gt;Reference Architecture — GCP&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*LihkT8HW_U5b8c4V14-n2A.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I hope you find this post useful, stay tuned for more, any feedback would be highly appreciated.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://www.youtube.com/channel/UCrIv4EU2tFX8VhhT0oCnDnw&quot;&gt;&lt;em&gt;YouTube&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">5 Tips for DS/AI Beginners &amp;amp; Enthusiasts</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2020/03/26/5-tips-for-ds-ai-beginners-enthusiasts.html" rel="alternate" type="text/html" title="5 Tips for DS/AI Beginners &amp; Enthusiasts" /><published>2020-03-26T00:00:00-05:00</published><updated>2020-03-26T00:00:00-05:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2020/03/26/5-tips-for-ds-ai-beginners-enthusiasts</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2020/03/26/5-tips-for-ds-ai-beginners-enthusiasts.html">&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*WYAntO3ZfXBMkyn31mHoRw.jpeg&quot; alt=&quot;Photo by [Sam Truong Dan](https://unsplash.com/@sam_truong?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/tips?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;In this post, I am sharing 5 important tips for budding data scientists, there is a bonus tip as well in the end.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;While I believe that the more you struggle, the more you get to learn in the process, you can still learn from experienced professionals to avoid common roadblocks or challenges.&lt;/p&gt;

&lt;p&gt;DS/AI starters and enthusiasts keep interacting with me and I try to help them. Apart from common questions by them, I give them tips on how they can become effective in their DS/AI journey, i.e. what to focus and what to avoid etc.&lt;/p&gt;

&lt;p&gt;Here I am sharing 5 of those tips:&lt;/p&gt;

&lt;h2 id=&quot;master-thebasics&quot;&gt;Master The Basics&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*KSja_FQfoEm-sRMao1VD6g.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Before you can work on any DS/AI problem, you need to master the basics. Understand the mathematics required for DS/AI, which is Linear Algebra, Multivariate Calculus, Statistics &amp;amp; Probability.&lt;/p&gt;

&lt;p&gt;Then learn about frequently used algorithms like Logistic Regression, Naive Bayes, Decision Trees, Random Forest etc. Where to apply which algorithm and what are the advantages and limitations of using a particular algorithm.&lt;/p&gt;

&lt;p&gt;Understand the overall process of working in DS/AI projects, from defining the problem to deploying the solution.&lt;/p&gt;

&lt;p&gt;Improve your coding skills to execute &amp;amp; validate your hypothesis efficiently. Python &amp;amp; R are the two major languages preferred by data scientists.&lt;/p&gt;

&lt;h2 id=&quot;learn-justenough&quot;&gt;Learn Just Enough&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*WzniU-FFsxpxKx5aglBU1g.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;DS/AI is a vast field, one can not be an expert overnight. The biggest mistake newbies do is to get stuck into an endless learning loop.&lt;/p&gt;

&lt;p&gt;You are learning DS/AI is to solve real-world problems, so learn just enough concepts to get started. Participate in hackathons/competitions, practice on public datasets.&lt;/p&gt;

&lt;p&gt;You need not read each book or attend every course on the planet before feeling confident to start with DS/AI. Just follow one decent book or course to build your basics and start working on problems. Keep the material (books &amp;amp; courses) for reference in case you get stuck with your problem.&lt;/p&gt;

&lt;h2 id=&quot;handle-data-like-apro&quot;&gt;Handle Data Like a Pro&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*YAYqqk7M7wQ28U7sVh1oQA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Data is the heart of DS/AI initiatives &amp;amp; projects. If you can’t handle data, you can’t make progress with your use case. Data handling can make or break any DS/AI project.&lt;/p&gt;

&lt;p&gt;Build your skills in data handling, learn frequently used tips &amp;amp; tricks in SQL, Pandas (in Python) or data.table (in R) to handle &amp;amp; manipulate data efficiently.&lt;/p&gt;

&lt;p&gt;Learn from Kaggle kernels, popular GitHub repos, how experts handle the data. Gather and clean public datasets on your own and refer these resources wherever get stuck.&lt;/p&gt;

&lt;h2 id=&quot;understand-thecontext&quot;&gt;Understand The Context&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/0*ChpN6CWwu61TEP-V.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As a newbie data scientist, you may be tempted to get the highest accuracy you can on any DS/AI problem you are working. But the real world is quite different, it’s not about the accuracy every time, many times robustness is very important and most of the time, the business may need models to be more interpretable.&lt;/p&gt;

&lt;p&gt;Every framework, every feature has its own use case. If a particular approach worked in your previous project, the same may not work in the current one. As we say, there is no silver bullet in DS/AI field.&lt;/p&gt;

&lt;p&gt;Hence understanding the context of the problem or the use case is important.&lt;/p&gt;

&lt;h2 id=&quot;improve-communication&quot;&gt;Improve Communication&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/0*9ZDJW08N1FZlPIFu.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To understand the problem or use case, to get the overall context from business, to explain outcomes of your complex models requires excellent communication skills.&lt;/p&gt;

&lt;p&gt;Presenting your approaches and findings to a non-technical audience, such as the marketing team or the CXOs, is a crucial part of being a data scientist.&lt;/p&gt;

&lt;p&gt;You need to have the ability to interpret data, tell the stories contained therein, and in general, communicate, write and present well. Presentation, Storytelling, Data Visualization, Writing/Publishing, Business Insights, all are part of communication skills.&lt;/p&gt;

&lt;p&gt;You may have to work hard to develop these skills — the same as you would with any technical skills. But with time and practice, you can get really good at it.&lt;/p&gt;

&lt;h2 id=&quot;bonus-tip-develop-t-shaped-skill-set&quot;&gt;Bonus Tip: Develop T-shaped Skill-set&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/0*5VE1BaIQGTmXCxIx.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;DS/AI is an interdisciplinary field, and you can get expertise in one area at a time. Still, I would suggest you develop T-shaped skill-set to collaborate better with experts in other related fields working with you in the project.&lt;/p&gt;

&lt;p&gt;T-shaped skills describe specific attributes of desirable workers. The vertical bar of the T refers to expert knowledge and experience in a particular area, while the top of the T refers to an ability to collaborate with experts in other disciplines and a willingness to use the knowledge gained from this collaboration. A t-shaped person is someone with t-shaped skills.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://www.youtube.com/channel/UCrIv4EU2tFX8VhhT0oCnDnw&quot;&gt;&lt;em&gt;YouTube&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">In this post, I am sharing 5 important tips for budding data scientists, there is a bonus tip as well in the end. While I believe that the more you struggle, the more you get to learn in the process, you can still learn from experienced professionals to avoid common roadblocks or challenges. DS/AI starters and enthusiasts keep interacting with me and I try to help them. Apart from common questions by them, I give them tips on how they can become effective in their DS/AI journey, i.e. what to focus and what to avoid etc. Here I am sharing 5 of those tips: Master The Basics Before you can work on any DS/AI problem, you need to master the basics. Understand the mathematics required for DS/AI, which is Linear Algebra, Multivariate Calculus, Statistics &amp;amp; Probability. Then learn about frequently used algorithms like Logistic Regression, Naive Bayes, Decision Trees, Random Forest etc. Where to apply which algorithm and what are the advantages and limitations of using a particular algorithm. Understand the overall process of working in DS/AI projects, from defining the problem to deploying the solution. Improve your coding skills to execute &amp;amp; validate your hypothesis efficiently. Python &amp;amp; R are the two major languages preferred by data scientists. Learn Just Enough DS/AI is a vast field, one can not be an expert overnight. The biggest mistake newbies do is to get stuck into an endless learning loop. You are learning DS/AI is to solve real-world problems, so learn just enough concepts to get started. Participate in hackathons/competitions, practice on public datasets. You need not read each book or attend every course on the planet before feeling confident to start with DS/AI. Just follow one decent book or course to build your basics and start working on problems. Keep the material (books &amp;amp; courses) for reference in case you get stuck with your problem. Handle Data Like a Pro Data is the heart of DS/AI initiatives &amp;amp; projects. If you can’t handle data, you can’t make progress with your use case. Data handling can make or break any DS/AI project. Build your skills in data handling, learn frequently used tips &amp;amp; tricks in SQL, Pandas (in Python) or data.table (in R) to handle &amp;amp; manipulate data efficiently. Learn from Kaggle kernels, popular GitHub repos, how experts handle the data. Gather and clean public datasets on your own and refer these resources wherever get stuck. Understand The Context As a newbie data scientist, you may be tempted to get the highest accuracy you can on any DS/AI problem you are working. But the real world is quite different, it’s not about the accuracy every time, many times robustness is very important and most of the time, the business may need models to be more interpretable. Every framework, every feature has its own use case. If a particular approach worked in your previous project, the same may not work in the current one. As we say, there is no silver bullet in DS/AI field. Hence understanding the context of the problem or the use case is important. Improve Communication To understand the problem or use case, to get the overall context from business, to explain outcomes of your complex models requires excellent communication skills. Presenting your approaches and findings to a non-technical audience, such as the marketing team or the CXOs, is a crucial part of being a data scientist. You need to have the ability to interpret data, tell the stories contained therein, and in general, communicate, write and present well. Presentation, Storytelling, Data Visualization, Writing/Publishing, Business Insights, all are part of communication skills. You may have to work hard to develop these skills — the same as you would with any technical skills. But with time and practice, you can get really good at it. Bonus Tip: Develop T-shaped Skill-set DS/AI is an interdisciplinary field, and you can get expertise in one area at a time. Still, I would suggest you develop T-shaped skill-set to collaborate better with experts in other related fields working with you in the project. T-shaped skills describe specific attributes of desirable workers. The vertical bar of the T refers to expert knowledge and experience in a particular area, while the top of the T refers to an ability to collaborate with experts in other disciplines and a willingness to use the knowledge gained from this collaboration. A t-shaped person is someone with t-shaped skills. Ankit Rathi is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture. Why don’t you connect with Ankit on YouTube, Twitter, LinkedIn or Instagram?</summary></entry><entry><title type="html">Useful Resources to Learn Artificial Intelligence</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2020/03/01/useful-resources-to-learn-artificial-intelligence.html" rel="alternate" type="text/html" title="Useful Resources to Learn Artificial Intelligence" /><published>2020-03-01T00:00:00-06:00</published><updated>2020-03-01T00:00:00-06:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2020/03/01/useful-resources-to-learn-artificial-intelligence</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2020/03/01/useful-resources-to-learn-artificial-intelligence.html">&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*6AyOAQu0Q9ivgvfeY9MIRQ.jpeg&quot; alt=&quot;Photo by [Markus Spiske](https://unsplash.com/photos/Q0mDOn9gWk8?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/resources?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;While you are learning Artificial Intelligence (AI) and looking to get into this exciting field, you may wonder which are the resources to refer, how do you know if a book or course is worth to spend time and/or money?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Due to close association between Data Science (DS), Machine Learning (ML) and Artificial Intelligence (AI), these terms have been used in this article interchangeably.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is not an exhaustive list by any means, but it is good enough to keep as your reference. You can build your own list of references once you get more awareness of the field.&lt;/p&gt;

&lt;p&gt;This post is my attempt to make your task easier. I am listing down major quality resources (mostly free) here and also going to provide you with my view of these resources, which will help you to make an informed decision.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*Ph24kcZtHvK51Pci0WFHSw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;You need not go through each and every resource mentioned here, I would suggest you build the foundation first using a course or a book and keep other resources for your reference.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;books-torefer&quot;&gt;Books to refer&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*KsUJovlo19BEon_wIynWNg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;machine-learning-withr&quot;&gt;Machine Learning with R&lt;/h3&gt;

&lt;p&gt;This is an excellent book for the R starter who wants to apply ML to any kind of project. All the main ML models are presented, as well as different performance metrics, bagging, pruning, tuning, ensembling etc. Easy to scan through, many tips with fully-solved textbook problems. Certainly, a very good starting point if you plan to compete on Kaggle. If you already master both R and ML, this books is obviously not for you.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Machine-Learning-R-Brett-Lantz-ebook/dp/B00G9581JM&quot;&gt;Machine Learning with R&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;python-machinelearning&quot;&gt;Python Machine Learning&lt;/h3&gt;

&lt;p&gt;This is a fantastic introductory book in machine learning with python. It provides enough background about the theory of each (covered) technique followed by its python code. One nice thing about the book is that it starts implementing Neural Networks from scratch, providing the reader with the chance of truly understanding the key underlying techniques such as back-propagation. Even further, the book presents an efficient (and professional) way of coding in python, the key to AI/ML.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Python-Machine-Learning-scikit-learn-TensorFlow/dp/1789955750&quot;&gt;Python Machine Learning&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;islr&quot;&gt;ISLR&lt;/h3&gt;

&lt;p&gt;The book explains the concepts of Statistical Learning from the very beginning. The core ideas such as bias-variance trade-off are deeply discussed and revisited in many problems. The included R examples are particularly helpful for beginners to learn R. The book also provides a brief, but concise description of functions’ parameters for many related R packages. Compared to &lt;em&gt;The Elements of Statistical Learning&lt;/em&gt;, it is easy for the reader to understand. It does a wonderful job of breaking things down complex concepts. If one wishes to learn more about a particular topic, I’d recommend The Element of Statistical Learning. These two pair nicely together.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Introduction-Statistical-Learning-Applications-Statistics/dp/1461471370&quot;&gt;An Introduction to Statistical Learning: with Applications in R&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;deep-learning&quot;&gt;Deep Learning&lt;/h3&gt;

&lt;p&gt;This is the book to read on deep learning. Written by luminaries in the field — if you’ve read any papers on deep learning, you must have heard about Goodfellow and Bengio before — and cutting through much of the BS surrounding the topic: like ‘big data’ before it, ‘deep learning’ is not something new and is not deserving of a special name. Networks with more hidden layers to detect higher-order features, networks of different types chained together in order to play to their strengths, graphs of networks to represent a probabilistic model.&lt;/p&gt;

&lt;p&gt;This is a theoretical book, but it can be read in tandem with &lt;em&gt;Hands-On Machine Learning with Scikit-Learn and TensorFlow&lt;/em&gt;, almost chapter-for-chapter. The Scikit-Learn and Tensorflow example code, while only moderately interesting on its own, helps to clarify the purpose of many of the topics in the Goodfellow book.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.deeplearningbook.org/&quot;&gt;Deep Learning&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;hands-on-machine-learning-with-scikit-learn-and-tensorflow&quot;&gt;Hands-On Machine Learning with Scikit-Learn and TensorFlow&lt;/h3&gt;

&lt;p&gt;This book provides a great introduction to machine learning for both developer and non-developers. Authors suggest to just go through even if you don’t understand math details. Highlights of this book are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Extraction of field expert knowledge is very important, you should know which model will serve better for the given solution. Luckily, a lot of models are available already from other scientists.&lt;/li&gt;
  &lt;li&gt;Training data is the most important part, the more you have it the better. So if you can you should accumulate as much data as you can, preferably categorized, you may not still know how you will apply the accumulated data in the future but you will need it.&lt;/li&gt;
  &lt;li&gt;Labelling training data is very important too, to train neural network you need to have at least thousands of labelled data samples, the more the better.&lt;/li&gt;
  &lt;li&gt;Machine learning algorithms and neural networks are pretty common for years but the latest breakthrough is possible because of new optimization, new autoencoders ( that may help to artificially generate training data) allowing to do training faster and with fewer data.&lt;/li&gt;
  &lt;li&gt;Machine learning is still pretty time and resources consuming process. To train a machine learning model you need to know how to tweak parameters and how to use different training approaches fitting the particular model.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The book demonstrates (including the code) different approaches using Scikit-Learn python package and also the TensorFlow.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1492032646&quot;&gt;Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;data-science-forbusiness&quot;&gt;Data Science for Business&lt;/h3&gt;

&lt;p&gt;This is probably the most practical book to read if you are looking for an overview of data science. Either you know when terms like k-means and ROC curves are to be used or you have some context when you start digging deeper into how some of these algorithms are implemented. You will find it at the right level because there is just enough math to explain the fundamental concepts and make them stick in your head.&lt;/p&gt;

&lt;p&gt;This isn’t a book on implementing these concepts or a bunch of algorithms. This gives the book the advantage of being something you can refer to an intelligent manager or interested developer, and they can both get a lot out of it. And if they are interested in the next level of learning there are plenty of pointers. You will also find the chapter on presenting results through ROC curves, lift curves, etc. pretty interesting. It would be cool if this book had some more hands-on, but you can go to Kaggle and browse around the current and past competitions to apply what you learn here.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Data-Science-Business-Data-Analytic-Thinking-ebook/dp/B00E6EQ3X4&quot;&gt;Data Science for Business&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;courses-toattend&quot;&gt;Courses to attend&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*Fnr5qOz0l3Iv94uDmiKAgg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;machine-learning&quot;&gt;Machine Learning&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*kXMhOBDVRMz1Yw23eW5oSQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Machine Learning is one of the first programming MOOCs. Coursera put online by Coursera founder and Stanford Professor Andrew Ng. This course assumes that you have basic programming skills and you have some understanding of Linear Algebra. Knowledge of Statistics &amp;amp; Probability is not required though.&lt;/p&gt;

&lt;p&gt;Andrew Ng does a good job explaining dense material and slides. The course gives you a lot of structure and direction for each homework, so it is generally pretty clear what you are supposed to do and how you are supposed to do it.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.coursera.org/learn/machine-learning&quot;&gt;Machine Learning by Andrew Ng&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;deep-learning-1&quot;&gt;Deep Learning&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*B-YNpNbYhL7H3aV3FGJJhQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;When you are rather new to the topic, you can learn a lot of doing the &lt;a href=&quot;https://www.deeplearning.ai/&quot;&gt;deeplearning.ai&lt;/a&gt; specialization. First and foremost, you learn the basic concepts of NN. How does a forward pass in simple sequential models look like, what’s a backpropagation, and so on? I experienced this set of courses as a very time-effective way to learn the basics and worth more than all the tutorials, blog posts and talks, which I went through beforehand.&lt;/p&gt;

&lt;p&gt;Doing this specialization is probably more than the first step into DL. I would say, each course is a single step in the right direction, so you end up with five steps in total. I think it builds a fundamental understanding of the field. But going further, you have to practice a lot and eventually it might be useful also to read more about the methodological background of DL variants. But doing the course work gets you started in a structured manner — which is worth a lot, especially in a field with so much buzz around it.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.coursera.org/specializations/deep-learning&quot;&gt;Deep Learning Specialization&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;fast-ai&quot;&gt;Fast AI&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*_zl5CsOf1wKVc5rf3nJtAQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If your goal is to be able to learn about deep learning and apply what you’ve learned, the fast.ai course is a better bet. If you have the time, interleaving the deeplearning.ai and fast.ai courses is ideal — you get the practical experience, applicability, and audience interaction of fast.ai, along with the organised material and theoretical explanations of deeplearning.ai.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://course.fast.ai/&quot;&gt;Fast AI Course&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;kaggle-learn&quot;&gt;Kaggle Learn&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*adt-vqwPcEbKqno-X-j54w.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Practical data skills you can apply immediately: that’s what you’ll learn in these free micro-courses. They’re the fastest (and most fun) way to become a data scientist or improve your current skills.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.kaggle.com/learn/overview&quot;&gt;Kaggle Learn&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;blogs-tofollow&quot;&gt;Blogs to follow&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*DPri3vSeJHubAvNX6qAdwQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;kd-nuggets&quot;&gt;KD Nuggets&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*PMf_rqIMEq7XmWMVo1DHaA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;KDnuggets is a leading site on AI, Analytics, Big Data, Data Mining, Data Science, and Machine Learning and is edited by Gregory Piatetsky-Shapiro and Matthew Mayo. KDnuggets was founded in February of 1997. Before that, Gregory maintained an earlier version of this site, called Knowledge Discovery Mine, at GTE Labs (1994 to 1997).&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.kdnuggets.com&quot;&gt;KD Nuggets&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;analytics-vidhya&quot;&gt;Analytics Vidhya&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*xdh0J0cjzco-Fm7-6dEVtA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Analytics Vidhya provides a community-based knowledge portal for Analytics and AI professionals. The aim of the platform is to become a complete portal serving all knowledge and career needs of Data Science Professionals.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.analyticsvidhya.com/blog/&quot;&gt;Analytics Vidhya&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;towards-datascience&quot;&gt;Towards Data Science&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*D9bFnt-SR_jwTCgdSLR3uA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;TDS joined Medium’s vibrant community in October 2016. In the beginning, their goal was simply to gather good posts and distribute them to a broader audience. Just a few months later, they were pleased to see that they had a very fast-growing audience and many new contributors.&lt;/p&gt;

&lt;p&gt;Today they are working with more than 10 Editorial Associates to prepare the most exciting content for our audience. They provide customized feedback to our contributors using Medium’s private notes. This allows them to promote their latest articles across social media without the added complexity that they might encounter using another platform.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://towardsdatascience.com&quot;&gt;Towards Data Science&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;podcasts-tolisten&quot;&gt;Podcasts to listen&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*my3rt5rEZQkm_OBmMbvfDg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;data-hack&quot;&gt;Data Hack&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*OTjq5-3vC8gk2pQ9W1Ummw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is Analytics Vidhya’s exclusive podcast series which will feature top leaders and practitioners in the artificial intelligence and machine learning industry.&lt;/p&gt;

&lt;p&gt;So in every episode of DataHack Radio, they bring you discussions with one such thought leader in the industry. They have discussions about their journey, their learnings and plenty of other AI-related things.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.analyticsvidhya.com/blog/category/podcast/&quot;&gt;Data Hack&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;super-datascience&quot;&gt;Super Data Science&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*11x3RqCGDCkDGENLCx5Haw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Kirill Eremenko&lt;/em&gt; is a Data Science coach and lifestyle entrepreneur. The goal of the &lt;em&gt;Super Data Science&lt;/em&gt; podcast is to bring you the most inspiring Data Scientists and Analysts from around the World to help you build your successful career in Data Science.&lt;/p&gt;

&lt;p&gt;Data is growing exponentially and so are salaries of those who work in analytics. This podcast can help you learn how to skyrocket your analytics career. Big Data, visualization, predictive modelling, forecasting, analysis, business processes, statistics, R, Python, SQL programming, tableau, machine learning, Hadoop, databases, data science MBAs, and all the analytics tools and skills that will help you better understand how to crush it in Data Science.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.superdatascience.com/podcast&quot;&gt;Super Data Science&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;the-oreilly-data-showpodcast&quot;&gt;The O’Reilly Data Show Podcast&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*GsfH3akVSuWLt9qO70zEOQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Known as the father of all other data shows, “the O’Reilly Data Show” features Ben Lorica, O’Reilly Media’s chief data scientist. Lorica conducts interviews with other experts about big data and data science current affairs. While it does get technical and may not be the best place for a beginner to start, it provides interesting insights into the future of the AI/ML industry.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.oreilly.com/radar/topics/oreilly-data-show-podcast/&quot;&gt;Data Show&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;youtube-channels&quot;&gt;YouTube Channels&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*-mzvQ--w0193VMdl2p_6lg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;deeplearningtv&quot;&gt;DeepLearning.TV&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*1GzebE9h8WVANeeInTXLYQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;DeepLearning.TV is all about Deep Learning, the field of study that teaches machines to perceive the world. Starting with a series that simplifies Deep Learning, the channel features topics such as How To’s, reviews of software libraries and applications, and interviews with key individuals in the field. Through a series of concept videos showcasing the intuition behind every Deep Learning method, they show you that Deep Learning is actually simpler than you think. Their goal is to improve your understanding of the topic so that you can better utilize Deep Learning in your own projects. They provide a window into the cutting edge of Deep Learning and bring you up to speed on what’s currently happening in the field.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/channel/UC9OeZkIwhzfv-_Cb7fCikLQ&quot;&gt;DeepLearning.TV&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;data-school&quot;&gt;Data School&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*ZLzNOlp1xjnha90gVqG5Ng.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Are you trying to learn data science so that you can get your first data science job? You’re probably confused about what you’re “supposed” to learn, and then you have the hardest time actually finding lessons you can understand! Data School focuses you on the topics you need to master first, and offers in-depth tutorials that you can understand regardless of your educational background.&lt;/p&gt;

&lt;p&gt;Your host here is Kevin Markham, and he is the founder of Data School. He has taught data science using the Python programming language to hundreds of students in the classroom, and hundreds of thousands of students (like you) online. Finding the right teacher was so important to his data science education, and so he sincerely hopes that he can be the right data science teacher for you.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/user/dataschool&quot;&gt;Data School&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;caltech-machinelearning&quot;&gt;Caltech Machine Learning&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*o0eLbvhc-GFtU8nfbaolGQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is an introductory course by Caltech Professor &lt;em&gt;Yaser Abu-Mostafa&lt;/em&gt; on machine learning that covers the basic theory, algorithms, and applications. Machine learning (ML) enables computational systems to adaptively improve their performance with experience accumulated from the observed data. ML techniques are widely applied in engineering, science, finance, and commerce to build systems for which we do not have a full mathematical specification (and that covers a lot of systems). The course balances theory and practice and covers the mathematical as well as the heuristic aspects.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLD63A284B7615313A\&quot;&gt;Caltech Machine Learning&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;github-repos&quot;&gt;GitHub Repos&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*jiAe0f6Cv7psXiFOmtr8DQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;awesome-datascience&quot;&gt;Awesome Data Science&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*cbw3xVbl67tXq9rCdrDhkQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This Repo answer the questions, “What is Data Science and what should you study to learn Data Science?” An awesome Data Science repository to learn and apply for real-world problems.&lt;/p&gt;

&lt;p&gt;As the aggregator says, “Our favourite data scientist is Clare Corthell. She is an expert in data-related systems and a hacker and has been working on a company as a data scientist. Clare’s blog. This website helps you to understand the exact way to study as a professional data scientist.”&lt;/p&gt;

&lt;p&gt;“Secondly, Our favourite programming language is &lt;em&gt;Python&lt;/em&gt; nowadays for Data Science. Python’s — Pandas library has full functionality for collecting and analyzing data. We use Anaconda to play with data and to create applications.”&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/academic/awesome-datascience&quot;&gt;Awesome Data Science&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;essential-cheat-sheets-for-machine-learning-and-deep-learning-engineers&quot;&gt;Essential Cheat Sheets for Machine Learning and Deep Learning Engineers&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*rJfSC9RVIKJS4GzizmMp2Q.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Machine learning is complex. For newbies, starting to learn machine learning can be painful if they don’t have the right resources to learn from. Most of the machine learning libraries are difficult to understand and the learning curve can be a bit frustrating. Kailash Ahirwar has created a repository on Github (&lt;a href=&quot;https://github.com/kailashahirwar/cheatsheets-ai&quot;&gt;cheatsheets-ai&lt;/a&gt;) containing cheatsheets for different machine learning frameworks, gathered from different sources. Have a look at the Github repository, also, contribute cheat sheets if you have any. Thanks.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/kailashahirwar/cheatsheets-ai&quot;&gt;Essential Cheat Sheets&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;hackermath-for-machinelearning&quot;&gt;HackerMath for Machine Learning&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*qOEVgyamB11p5sYwfhBcKg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Math literacy, including proficiency in Linear Algebra and Statistics, is a must for anyone pursuing a career in data science. The goal of this workshop is to introduce some key concepts from these domains that get used repeatedly in data science/AI applications.&lt;/p&gt;

&lt;p&gt;As outlined by Amit Kapoor, “Our approach is what we call the ‘Hacker’s way’. Instead of going back to formulae and proofs, we teach the concepts by writing code. And in practical applications. Concepts don’t remain sticky if the usage is never taught.”&lt;/p&gt;

&lt;p&gt;The focus here is on depth rather than breadth. Three areas are chosen — Hypothesis Testing, Supervised Learning and Unsupervised Learning. They are covered to sufficient depth — 50% of the time on the concepts and 50% of the time spent coding them.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/amitkaps/hackermath&quot;&gt;HackerMath for Machine Learning&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So this is all that I needed to cover in this article. Now you know what useful resources you need to keep handy in order to get proficient in the field of AI.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://www.youtube.com/channel/UCrIv4EU2tFX8VhhT0oCnDnw&quot;&gt;&lt;em&gt;YouTube&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">While you are learning Artificial Intelligence (AI) and looking to get into this exciting field, you may wonder which are the resources to refer, how do you know if a book or course is worth to spend time and/or money? Due to close association between Data Science (DS), Machine Learning (ML) and Artificial Intelligence (AI), these terms have been used in this article interchangeably. This is not an exhaustive list by any means, but it is good enough to keep as your reference. You can build your own list of references once you get more awareness of the field. This post is my attempt to make your task easier. I am listing down major quality resources (mostly free) here and also going to provide you with my view of these resources, which will help you to make an informed decision. You need not go through each and every resource mentioned here, I would suggest you build the foundation first using a course or a book and keep other resources for your reference. Books to refer Machine Learning with R This is an excellent book for the R starter who wants to apply ML to any kind of project. All the main ML models are presented, as well as different performance metrics, bagging, pruning, tuning, ensembling etc. Easy to scan through, many tips with fully-solved textbook problems. Certainly, a very good starting point if you plan to compete on Kaggle. If you already master both R and ML, this books is obviously not for you. Machine Learning with R Python Machine Learning This is a fantastic introductory book in machine learning with python. It provides enough background about the theory of each (covered) technique followed by its python code. One nice thing about the book is that it starts implementing Neural Networks from scratch, providing the reader with the chance of truly understanding the key underlying techniques such as back-propagation. Even further, the book presents an efficient (and professional) way of coding in python, the key to AI/ML. Python Machine Learning ISLR The book explains the concepts of Statistical Learning from the very beginning. The core ideas such as bias-variance trade-off are deeply discussed and revisited in many problems. The included R examples are particularly helpful for beginners to learn R. The book also provides a brief, but concise description of functions’ parameters for many related R packages. Compared to The Elements of Statistical Learning, it is easy for the reader to understand. It does a wonderful job of breaking things down complex concepts. If one wishes to learn more about a particular topic, I’d recommend The Element of Statistical Learning. These two pair nicely together. An Introduction to Statistical Learning: with Applications in R Deep Learning This is the book to read on deep learning. Written by luminaries in the field — if you’ve read any papers on deep learning, you must have heard about Goodfellow and Bengio before — and cutting through much of the BS surrounding the topic: like ‘big data’ before it, ‘deep learning’ is not something new and is not deserving of a special name. Networks with more hidden layers to detect higher-order features, networks of different types chained together in order to play to their strengths, graphs of networks to represent a probabilistic model. This is a theoretical book, but it can be read in tandem with Hands-On Machine Learning with Scikit-Learn and TensorFlow, almost chapter-for-chapter. The Scikit-Learn and Tensorflow example code, while only moderately interesting on its own, helps to clarify the purpose of many of the topics in the Goodfellow book. Deep Learning Hands-On Machine Learning with Scikit-Learn and TensorFlow This book provides a great introduction to machine learning for both developer and non-developers. Authors suggest to just go through even if you don’t understand math details. Highlights of this book are: Extraction of field expert knowledge is very important, you should know which model will serve better for the given solution. Luckily, a lot of models are available already from other scientists. Training data is the most important part, the more you have it the better. So if you can you should accumulate as much data as you can, preferably categorized, you may not still know how you will apply the accumulated data in the future but you will need it. Labelling training data is very important too, to train neural network you need to have at least thousands of labelled data samples, the more the better. Machine learning algorithms and neural networks are pretty common for years but the latest breakthrough is possible because of new optimization, new autoencoders ( that may help to artificially generate training data) allowing to do training faster and with fewer data. Machine learning is still pretty time and resources consuming process. To train a machine learning model you need to know how to tweak parameters and how to use different training approaches fitting the particular model. The book demonstrates (including the code) different approaches using Scikit-Learn python package and also the TensorFlow. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow Data Science for Business This is probably the most practical book to read if you are looking for an overview of data science. Either you know when terms like k-means and ROC curves are to be used or you have some context when you start digging deeper into how some of these algorithms are implemented. You will find it at the right level because there is just enough math to explain the fundamental concepts and make them stick in your head. This isn’t a book on implementing these concepts or a bunch of algorithms. This gives the book the advantage of being something you can refer to an intelligent manager or interested developer, and they can both get a lot out of it. And if they are interested in the next level of learning there are plenty of pointers. You will also find the chapter on presenting results through ROC curves, lift curves, etc. pretty interesting. It would be cool if this book had some more hands-on, but you can go to Kaggle and browse around the current and past competitions to apply what you learn here. Data Science for Business Courses to attend Machine Learning Machine Learning is one of the first programming MOOCs. Coursera put online by Coursera founder and Stanford Professor Andrew Ng. This course assumes that you have basic programming skills and you have some understanding of Linear Algebra. Knowledge of Statistics &amp;amp; Probability is not required though. Andrew Ng does a good job explaining dense material and slides. The course gives you a lot of structure and direction for each homework, so it is generally pretty clear what you are supposed to do and how you are supposed to do it. Machine Learning by Andrew Ng Deep Learning When you are rather new to the topic, you can learn a lot of doing the deeplearning.ai specialization. First and foremost, you learn the basic concepts of NN. How does a forward pass in simple sequential models look like, what’s a backpropagation, and so on? I experienced this set of courses as a very time-effective way to learn the basics and worth more than all the tutorials, blog posts and talks, which I went through beforehand. Doing this specialization is probably more than the first step into DL. I would say, each course is a single step in the right direction, so you end up with five steps in total. I think it builds a fundamental understanding of the field. But going further, you have to practice a lot and eventually it might be useful also to read more about the methodological background of DL variants. But doing the course work gets you started in a structured manner — which is worth a lot, especially in a field with so much buzz around it. Deep Learning Specialization Fast AI If your goal is to be able to learn about deep learning and apply what you’ve learned, the fast.ai course is a better bet. If you have the time, interleaving the deeplearning.ai and fast.ai courses is ideal — you get the practical experience, applicability, and audience interaction of fast.ai, along with the organised material and theoretical explanations of deeplearning.ai. Fast AI Course Kaggle Learn Practical data skills you can apply immediately: that’s what you’ll learn in these free micro-courses. They’re the fastest (and most fun) way to become a data scientist or improve your current skills. Kaggle Learn Blogs to follow KD Nuggets KDnuggets is a leading site on AI, Analytics, Big Data, Data Mining, Data Science, and Machine Learning and is edited by Gregory Piatetsky-Shapiro and Matthew Mayo. KDnuggets was founded in February of 1997. Before that, Gregory maintained an earlier version of this site, called Knowledge Discovery Mine, at GTE Labs (1994 to 1997). KD Nuggets Analytics Vidhya Analytics Vidhya provides a community-based knowledge portal for Analytics and AI professionals. The aim of the platform is to become a complete portal serving all knowledge and career needs of Data Science Professionals. Analytics Vidhya Towards Data Science TDS joined Medium’s vibrant community in October 2016. In the beginning, their goal was simply to gather good posts and distribute them to a broader audience. Just a few months later, they were pleased to see that they had a very fast-growing audience and many new contributors. Today they are working with more than 10 Editorial Associates to prepare the most exciting content for our audience. They provide customized feedback to our contributors using Medium’s private notes. This allows them to promote their latest articles across social media without the added complexity that they might encounter using another platform. Towards Data Science Podcasts to listen Data Hack This is Analytics Vidhya’s exclusive podcast series which will feature top leaders and practitioners in the artificial intelligence and machine learning industry. So in every episode of DataHack Radio, they bring you discussions with one such thought leader in the industry. They have discussions about their journey, their learnings and plenty of other AI-related things. Data Hack Super Data Science Kirill Eremenko is a Data Science coach and lifestyle entrepreneur. The goal of the Super Data Science podcast is to bring you the most inspiring Data Scientists and Analysts from around the World to help you build your successful career in Data Science. Data is growing exponentially and so are salaries of those who work in analytics. This podcast can help you learn how to skyrocket your analytics career. Big Data, visualization, predictive modelling, forecasting, analysis, business processes, statistics, R, Python, SQL programming, tableau, machine learning, Hadoop, databases, data science MBAs, and all the analytics tools and skills that will help you better understand how to crush it in Data Science. Super Data Science The O’Reilly Data Show Podcast Known as the father of all other data shows, “the O’Reilly Data Show” features Ben Lorica, O’Reilly Media’s chief data scientist. Lorica conducts interviews with other experts about big data and data science current affairs. While it does get technical and may not be the best place for a beginner to start, it provides interesting insights into the future of the AI/ML industry. Data Show YouTube Channels DeepLearning.TV DeepLearning.TV is all about Deep Learning, the field of study that teaches machines to perceive the world. Starting with a series that simplifies Deep Learning, the channel features topics such as How To’s, reviews of software libraries and applications, and interviews with key individuals in the field. Through a series of concept videos showcasing the intuition behind every Deep Learning method, they show you that Deep Learning is actually simpler than you think. Their goal is to improve your understanding of the topic so that you can better utilize Deep Learning in your own projects. They provide a window into the cutting edge of Deep Learning and bring you up to speed on what’s currently happening in the field. DeepLearning.TV Data School Are you trying to learn data science so that you can get your first data science job? You’re probably confused about what you’re “supposed” to learn, and then you have the hardest time actually finding lessons you can understand! Data School focuses you on the topics you need to master first, and offers in-depth tutorials that you can understand regardless of your educational background. Your host here is Kevin Markham, and he is the founder of Data School. He has taught data science using the Python programming language to hundreds of students in the classroom, and hundreds of thousands of students (like you) online. Finding the right teacher was so important to his data science education, and so he sincerely hopes that he can be the right data science teacher for you. Data School Caltech Machine Learning This is an introductory course by Caltech Professor Yaser Abu-Mostafa on machine learning that covers the basic theory, algorithms, and applications. Machine learning (ML) enables computational systems to adaptively improve their performance with experience accumulated from the observed data. ML techniques are widely applied in engineering, science, finance, and commerce to build systems for which we do not have a full mathematical specification (and that covers a lot of systems). The course balances theory and practice and covers the mathematical as well as the heuristic aspects. Caltech Machine Learning GitHub Repos Awesome Data Science This Repo answer the questions, “What is Data Science and what should you study to learn Data Science?” An awesome Data Science repository to learn and apply for real-world problems. As the aggregator says, “Our favourite data scientist is Clare Corthell. She is an expert in data-related systems and a hacker and has been working on a company as a data scientist. Clare’s blog. This website helps you to understand the exact way to study as a professional data scientist.” “Secondly, Our favourite programming language is Python nowadays for Data Science. Python’s — Pandas library has full functionality for collecting and analyzing data. We use Anaconda to play with data and to create applications.” Awesome Data Science Essential Cheat Sheets for Machine Learning and Deep Learning Engineers Machine learning is complex. For newbies, starting to learn machine learning can be painful if they don’t have the right resources to learn from. Most of the machine learning libraries are difficult to understand and the learning curve can be a bit frustrating. Kailash Ahirwar has created a repository on Github (cheatsheets-ai) containing cheatsheets for different machine learning frameworks, gathered from different sources. Have a look at the Github repository, also, contribute cheat sheets if you have any. Thanks. Essential Cheat Sheets HackerMath for Machine Learning Math literacy, including proficiency in Linear Algebra and Statistics, is a must for anyone pursuing a career in data science. The goal of this workshop is to introduce some key concepts from these domains that get used repeatedly in data science/AI applications. As outlined by Amit Kapoor, “Our approach is what we call the ‘Hacker’s way’. Instead of going back to formulae and proofs, we teach the concepts by writing code. And in practical applications. Concepts don’t remain sticky if the usage is never taught.” The focus here is on depth rather than breadth. Three areas are chosen — Hypothesis Testing, Supervised Learning and Unsupervised Learning. They are covered to sufficient depth — 50% of the time on the concepts and 50% of the time spent coding them. HackerMath for Machine Learning So this is all that I needed to cover in this article. Now you know what useful resources you need to keep handy in order to get proficient in the field of AI. Ankit Rathi is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture. Why don’t you connect with Ankit on YouTube, Twitter, LinkedIn or Instagram?</summary></entry><entry><title type="html">Basic ML/AI Pipeline in Python</title><link href="https://ankit-rathi.github.io/data-and-ai/jupyter/2020/02/14/DataScience_Pipeline.html" rel="alternate" type="text/html" title="Basic ML/AI Pipeline in Python" /><published>2020-02-14T00:00:00-06:00</published><updated>2020-02-14T00:00:00-06:00</updated><id>https://ankit-rathi.github.io/data-and-ai/jupyter/2020/02/14/DataScience_Pipeline</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/jupyter/2020/02/14/DataScience_Pipeline.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-02-14-DataScience_Pipeline.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# import basic libraries&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pd&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;warnings&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;warnings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filterwarnings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;ignore&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# import plot libraries&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;seaborn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sns&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Set2&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;matplotlib&lt;/span&gt; inline

&lt;span class=&quot;c1&quot;&gt;# import ml libraries&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LabelEncoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MinMaxScaler&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cross_val_score&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.ensemble&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RandomForestClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RandomForestRegressor&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy_score&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.svm&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LinearSVC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SVC&lt;/span&gt;



&lt;span class=&quot;c1&quot;&gt;# categories v1, v4, v8, v9, v11, v12, v16, classLabel&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LabelEncoder&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LabelEncoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# list number of files&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;listdir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;data&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# import data&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;subprocess&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check_output&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;check_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;ls&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;../input/&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;utf8&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;data/train.csv&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;data/test.csv&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# check shape&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Train rows and columns : &amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Test rows and columns : &amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# check column types&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ctype&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dtypes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ctype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Count&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;Column Type&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ctype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Column Type&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aggregate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;count&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# display data&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# numerical data distribution&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;describe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# categorical data distribution&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;describe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;include&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;O&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# check missing values&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;missing_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isnull&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;missing_df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;column_name&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;missing_count&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;missing_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;missing_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;missing_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;missing_count&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;missing_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;missing_df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;missing_count&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;missing_df&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# impute/treat missing values&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;col1&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;col1&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fillna&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;col1&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# for categorical&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;col2&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fillna&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;col2&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# for numerical (mean or median)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# check ouliers&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fmean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fstd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;col&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# upper outliers&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fmean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fstd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;col&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# lower outliers&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# treat outliers&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;fmean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fstd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fmean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fstd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;col&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fmean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fstd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# treat upper outliers&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fmean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fstd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;col&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fmean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fstd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# treat lower outliers&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# univariate analysis&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# histogram of numerical column&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;num&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bins&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kde&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;num&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;num histogram&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# charts of categorical column&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;col&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;col&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# pie plot for categorical column&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fig1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ax1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;autopct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%1.1f%%&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shadow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ax1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;equal&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# bar plot for categorical column&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fig2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;countplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;col&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# bivariate analysis&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;barplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;cat1&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;cat2&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# categorical vs categorical&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;violinplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;cat&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;num&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# categorical vs numerical&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;regplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;num1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;num2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# numerical vs numerical&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# multivariate analysis &lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cols_to_use&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;corrmat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;spearman&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heatmap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corrmat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vmax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;square&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;YlGnBu&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;annot&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;numerical variables correlation map&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# split data&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;target&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;123&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# feature engineering on train/valid&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LabelEncoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;cat&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;cat&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# for categorical data&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;scaler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MinMaxScaler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# for numerical data&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;scaler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                      
&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scaler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scaler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# build model on train&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LogisticRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# RandomForestClassifier(), SVC(), RandomForestRegressor() etc&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# evaluate on valid&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# for categorical target&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;mean_squared_error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# for numerical target&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# k-fold cross-validation&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;svm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SVC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kernel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;linear&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cross_val_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Score: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%0.2f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; (+/- &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%0.2f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;)&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;                   
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# hyper-parameter tuning&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# for each combination of parameters,&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# train an SVC&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;svm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SVC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# perform cross-validation&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cross_val_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;svm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# compute mean cross-validation accuracy&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# if we got a better score, store the score and parameters&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;best_score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;best_parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;C&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;gamma&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# rebuild a model on the combined training and validation set&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;svm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SVC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;svm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# ensembling/stacking&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# to be continued...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Artificial Intelligence from Novice to Professional</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2020/01/23/artificial-intelligence-from-novice-to-professional.html" rel="alternate" type="text/html" title="Artificial Intelligence from Novice to Professional" /><published>2020-01-23T00:00:00-06:00</published><updated>2020-01-23T00:00:00-06:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2020/01/23/artificial-intelligence-from-novice-to-professional</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2020/01/23/artificial-intelligence-from-novice-to-professional.html">&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*PNtNefJMXMdi0JwUA2YWRA.png&quot; alt=&quot;Photo by [Ben White](https://unsplash.com/@benwhitephotography?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText)/[Hunters Race](https://unsplash.com/@huntersrace?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/faceless-person?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText)&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;why-thispost&quot;&gt;Why this post?&lt;/h2&gt;

&lt;p&gt;There is a general notion that Artificial Intelligence is all about algorithms. If you look around most of the courses, books, blogs, etc, you will find that most of them cover how you can apply certain algorithms and further optimize those algorithms.&lt;/p&gt;

&lt;p&gt;After working on a few real-world AI/ML projects, you will realize that while algorithms are at the core, AI is much more than algorithms. From identifying &amp;amp; assessing AI opportunities in your organization/department to deploying and maintaining the solutions in production, a lot goes into AI/ML projects.&lt;/p&gt;

&lt;p&gt;In this post, I am going to briefly touch every aspect of AI/ML project lifecycle. The good news is, as a data scientist you need not master every aspect, but knowing those areas to some extent will help you contribute better in real-world projects.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A single post can’t make you an AI professional, but it can ask relevant questions &amp;amp; increase awareness, seeking answers to these questions can help you build your own AI roadmap.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We can segregate all these aspects of AI into 5 parts: AI Introduction, AI Pre-requisites, AI Concepts &amp;amp; Algorithms, Enterprise AI &amp;amp; Peripherals of AI&lt;/p&gt;

&lt;h2 id=&quot;i-ai-introduction&quot;&gt;I. AI Introduction&lt;/h2&gt;

&lt;p&gt;AI is a team game, every aspiring AI role needs to have a common understanding of AI/ML field. This part covers a simple What, Why &amp;amp; How of AI:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;— Why you should learn AI?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;— Why AI is important?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;— What is Artificial Intelligence?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;— How an end-to-end AI project looks like?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;— What are the roles in AI projects and who does what?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;ii-ai-pre-requisites&quot;&gt;II. AI Pre-requisites&lt;/h2&gt;

&lt;p&gt;AI/ML has a steep learning curve because it is an amalgamation of many fields (Statistics, IT &amp;amp; Domain etc). And some knowledge of these fields is required before you can start grasping AI/ML concepts. This part covers the pre-requisites of AI:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;— What topics of maths you should cover?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;— What programming languages, libraries &amp;amp; frameworks you should be aware of?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;— How does data move in an organization?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;— How is it stored and processed?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;iii-ai-concepts--algorithms&quot;&gt;III. AI Concepts &amp;amp; Algorithms&lt;/h2&gt;

&lt;p&gt;AI/ML in itself is quite a vast field and have different techniques and frameworks to deal with different kind of real-world problems. This part covers major AI/ML techniques and what to use when:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;— What are the major types of AI techniques?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;— When to use what? Main concepts &amp;amp; algorithms ML, DL &amp;amp; RL?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;iv-enterprise-ai&quot;&gt;IV. Enterprise AI&lt;/h2&gt;

&lt;p&gt;Learning AI/ML concepts &amp;amp; algorithms are not enough, you will be solving some business problems with what you have learned. You need to be aware of what happens when these concepts &amp;amp; algorithms are applied within an enterprise. This part covers the aspects of enterprise AI:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;- What is the difference between Hackathons &amp;amp; Real-world projects?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;- How to operationalize AI?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;- How to build AI Strategy?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;- Why ethics &amp;amp; explainability is important &amp;amp; how can we make AI explainable?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;v-peripherals-ofai&quot;&gt;V. Peripherals of AI&lt;/h2&gt;

&lt;p&gt;Apart from learning concepts and their applications, you may have specific needs at the moment like you want to get into the AI field or you need to lead an AI initiative in your organization. This part covers those specific needs:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;- How you can get into AI field?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;- How to lead AI initiatives in your organization?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;- How to future-proof your AI career?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;I hope by now you have got an idea of what it takes to work on AI projects in the real world. Due to different but overlapping fields, it is really hard to get in-depth knowledge of every aspect of an AI aspirant.&lt;/p&gt;

&lt;p&gt;But what you can do is to build a T-shape skill-set in the AI field, where you go in-depth in the aspect of your choice and have handy knowledge of other related aspects.&lt;/p&gt;

&lt;p&gt;I will cover the above-mentioned aspects of AI thoroughly in upcoming posts, stay tuned.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://www.youtube.com/channel/UCrIv4EU2tFX8VhhT0oCnDnw&quot;&gt;&lt;em&gt;YouTube&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Why this post? There is a general notion that Artificial Intelligence is all about algorithms. If you look around most of the courses, books, blogs, etc, you will find that most of them cover how you can apply certain algorithms and further optimize those algorithms. After working on a few real-world AI/ML projects, you will realize that while algorithms are at the core, AI is much more than algorithms. From identifying &amp;amp; assessing AI opportunities in your organization/department to deploying and maintaining the solutions in production, a lot goes into AI/ML projects. In this post, I am going to briefly touch every aspect of AI/ML project lifecycle. The good news is, as a data scientist you need not master every aspect, but knowing those areas to some extent will help you contribute better in real-world projects. A single post can’t make you an AI professional, but it can ask relevant questions &amp;amp; increase awareness, seeking answers to these questions can help you build your own AI roadmap. We can segregate all these aspects of AI into 5 parts: AI Introduction, AI Pre-requisites, AI Concepts &amp;amp; Algorithms, Enterprise AI &amp;amp; Peripherals of AI I. AI Introduction AI is a team game, every aspiring AI role needs to have a common understanding of AI/ML field. This part covers a simple What, Why &amp;amp; How of AI: — Why you should learn AI? — Why AI is important? — What is Artificial Intelligence? — How an end-to-end AI project looks like? — What are the roles in AI projects and who does what? II. AI Pre-requisites AI/ML has a steep learning curve because it is an amalgamation of many fields (Statistics, IT &amp;amp; Domain etc). And some knowledge of these fields is required before you can start grasping AI/ML concepts. This part covers the pre-requisites of AI: — What topics of maths you should cover? — What programming languages, libraries &amp;amp; frameworks you should be aware of? — How does data move in an organization? — How is it stored and processed? III. AI Concepts &amp;amp; Algorithms AI/ML in itself is quite a vast field and have different techniques and frameworks to deal with different kind of real-world problems. This part covers major AI/ML techniques and what to use when: — What are the major types of AI techniques? — When to use what? Main concepts &amp;amp; algorithms ML, DL &amp;amp; RL? IV. Enterprise AI Learning AI/ML concepts &amp;amp; algorithms are not enough, you will be solving some business problems with what you have learned. You need to be aware of what happens when these concepts &amp;amp; algorithms are applied within an enterprise. This part covers the aspects of enterprise AI: - What is the difference between Hackathons &amp;amp; Real-world projects? - How to operationalize AI? - How to build AI Strategy? - Why ethics &amp;amp; explainability is important &amp;amp; how can we make AI explainable? V. Peripherals of AI Apart from learning concepts and their applications, you may have specific needs at the moment like you want to get into the AI field or you need to lead an AI initiative in your organization. This part covers those specific needs: - How you can get into AI field? - How to lead AI initiatives in your organization? - How to future-proof your AI career? Conclusion I hope by now you have got an idea of what it takes to work on AI projects in the real world. Due to different but overlapping fields, it is really hard to get in-depth knowledge of every aspect of an AI aspirant. But what you can do is to build a T-shape skill-set in the AI field, where you go in-depth in the aspect of your choice and have handy knowledge of other related aspects. I will cover the above-mentioned aspects of AI thoroughly in upcoming posts, stay tuned. Ankit Rathi is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture. Why don’t you connect with Ankit on YouTube, Twitter, LinkedIn or Instagram?</summary></entry><entry><title type="html">Building Blocks of Artificial Intelligence</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2019/12/27/building-blocks-of-artificial-intelligence.html" rel="alternate" type="text/html" title="Building Blocks of Artificial Intelligence" /><published>2019-12-27T00:00:00-06:00</published><updated>2019-12-27T00:00:00-06:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2019/12/27/building-blocks-of-artificial-intelligence</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2019/12/27/building-blocks-of-artificial-intelligence.html">&lt;p&gt;Title: Building Blocks of Artificial Intelligence
Date: 2019-12-27 17:10
Author: ankitrathi
Category: Uncategorized
Tags: Artificial Intelligence, Building Blocks, Data Science, Machine Learning, Towards Data Science
Slug: building-blocks-of-artificial-intelligence
Status: published&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/1*jQQ7PSA9MQXa0FTdS19EHA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are a few core skills in every job. To perform that job, you need to be aware of core concepts, you need to be aware of the end to end process and you need to learn how to use related tools to perform that job. Artificial Intelligence is no different, it has its own core concepts, processes and tools.&lt;/p&gt;

&lt;p&gt;This post covers the core concepts you need to learn, the end-to-end process you need to be aware of &amp;amp; important tools you need to master to work as a data scientist.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*rhRKmQu9vXKYuzHOftQ05Q.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Please note that this post only outlines the concepts, processes and tools used by data scientists. I will publish the resources (mostly free) for these topics in upcoming post.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;concepts-tolearn&quot;&gt;Concepts to learn&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*IQdUsr1L1EjjGRJTVxXzlw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;mathematics&quot;&gt;Mathematics&lt;/h3&gt;

&lt;p&gt;Artificial Intelligence contains math — no avoiding that! This section is for learners about basic math they need in order to be successful in almost any AI project/problem. So let’s start:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Multivariate Calculus&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Calculus is a set of tools for analyzing the relationship between functions and their inputs. In Multivariate Calculus, we can take a function with multiple inputs and determine the influence of each of them separately.&lt;/p&gt;

&lt;p&gt;In AI, we try to find the inputs which enable a function to best match the data. The slope or descent describes the rate of change off the output with respect to an input. Determining the influence of each input on the output is also one of the critical tasks. All this requires a solid understanding of Multivariate Calculus.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Linear Algebra&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The word &lt;em&gt;algebra&lt;/em&gt; comes from the Arabi word “&lt;em&gt;al-jabr&lt;/em&gt;” which means “&lt;em&gt;the reunion of broken parts&lt;/em&gt;”. This is the collection of methods deriving unknowns from knowns in mathematics. &lt;em&gt;Linear Algebra&lt;/em&gt; is the branch that deals with &lt;em&gt;linear equations&lt;/em&gt; and &lt;em&gt;linear functions&lt;/em&gt; which are represented through &lt;em&gt;matrices&lt;/em&gt; and &lt;em&gt;vectors&lt;/em&gt;. In simpler words, it helps us understand geometric terms such as planes, in higher dimensions, and perform mathematical operations on them. By definition, algebra deals primarily with scalars (one-dimensional entities), but Linear Algebra has vectors and matrices (entities which possess two or more dimensional components) to deal with linear equations and functions.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Linear Algebra&lt;/em&gt; is central to almost all areas of mathematics like &lt;em&gt;geometry&lt;/em&gt; and &lt;em&gt;functional analysis&lt;/em&gt;. Its concepts are a crucial prerequisite for understanding the theory behind &lt;em&gt;AI&lt;/em&gt;. You don’t need to understand &lt;em&gt;Linear Algebra&lt;/em&gt; before getting started in &lt;em&gt;AI&lt;/em&gt;, but at some point, you may want to gain a better understanding of how the &lt;em&gt;different algorithms&lt;/em&gt; really work under the hood. So if you really want to be a professional in this field, you will have to master the parts of &lt;em&gt;Linear Algebra&lt;/em&gt; that are important for &lt;em&gt;AI&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Statistics &amp;amp; Probability&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Statistics&lt;/em&gt; is a mathematical body of science that pertains to the &lt;em&gt;collection&lt;/em&gt;, &lt;em&gt;analysis&lt;/em&gt;, &lt;em&gt;interpretation&lt;/em&gt; or &lt;em&gt;explanation&lt;/em&gt;, and &lt;em&gt;presentation&lt;/em&gt; of data. Probability is the chance that something will happen — how likely it is that some event will happen.&lt;/p&gt;

&lt;p&gt;Statistics help you to understand your data and is an initial &amp;amp; very important step of AI. This is due to the fact that AI is all about making predictions and you can’t predict if you can’t understand the patterns in existing data.&lt;/p&gt;

&lt;p&gt;Uncertainty and randomness occur in many aspects of our daily life and having a good knowledge of probability helps us make sense of these uncertainties. Learning about probability helps us make informed judgments on what is likely to happen, based on a pattern of data collected previously or an estimate.&lt;/p&gt;

&lt;p&gt;AI often uses statistical inferences to predict or analyze trends from data, while statistical inferences use probability distributions of data. Hence knowing probability &amp;amp; statistics and its applications are important to work effectively on AI problems.&lt;/p&gt;

&lt;h3 id=&quot;programming&quot;&gt;Programming&lt;/h3&gt;

&lt;p&gt;To execute the AI pipeline, you need to learn algorithm design as well as fundamental programming concepts such as data selection, iteration and functional decomposition, data abstraction and organisation. In addition to this, you need to learn how to perform simple data visualizations using programming and embed your learning using problem-based assignments.&lt;/p&gt;

&lt;h3 id=&quot;machine-learning-algorithms&quot;&gt;Machine Learning Algorithms&lt;/h3&gt;

&lt;p&gt;Machine learning algorithms can be divided into 3 broad categories —&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Supervised learning,&lt;/li&gt;
  &lt;li&gt;Unsupervised learning&lt;/li&gt;
  &lt;li&gt;Reinforcement learning.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Supervised learning is useful in cases where a property (&lt;em&gt;label&lt;/em&gt;) is available for a certain dataset (&lt;em&gt;training set&lt;/em&gt;) but is missing and needs to be predicted for other instances. Unsupervised learning is useful in cases where the challenge is to discover implicit relationships in a given &lt;em&gt;unlabeled&lt;/em&gt; dataset (items are not pre-assigned). Reinforcement learning falls between these 2 extremes — there is some form of feedback available for each predictive step or action, but no precise label or error message.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Intrinsic details of various algorithms is not in scope of this series, you can refer the resources mentioned in the next post to learn them.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Supervised learning can be further divided into Regression (Linear, Non-linear, etc) &amp;amp; Classification (Logistics Regression, Decision Tree, Naïve Bayes etc) algorithms. Some algorithms can be used for regression as well as classification i.e. Random Forests, Support Vector Machines, etc.&lt;/p&gt;

&lt;p&gt;Unsupervised learning can also be further divided into Clustering, Anomaly Detection, Associative Mining.&lt;/p&gt;

&lt;p&gt;Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward.&lt;/p&gt;

&lt;h3 id=&quot;deep-learning-frameworks&quot;&gt;Deep Learning Frameworks&lt;/h3&gt;

&lt;p&gt;Deep learning frameworks are a more advanced form of ML and solve specific problems where data is either unstructured or huge or both. Neural Nets, CNNs, RNNs &amp;amp; LSTM, GANs are the frameworks one needs to be aware of.&lt;/p&gt;

&lt;h3 id=&quot;domain-knowledge&quot;&gt;Domain Knowledge&lt;/h3&gt;

&lt;p&gt;This lack of domain knowledge, while perfectly understandable, can be a major barrier to data scientists. For one thing, it’s difficult to come up with project ideas in a domain that you don’t know much about. It can also be difficult to determine the type of data that may be helpful for a project — if you want to build a model to predict an outcome, you need to know what types of variables might be related to this outcome so you can make sure to gather the right data.&lt;/p&gt;

&lt;p&gt;Knowing the domain is useful not only for figuring out projects and how to approach them but also for having rules of thumb for sanity checks on the data. Knowing how data is captured (is it hand-entered? Is it from machines that can give false readings for any number of reasons?) can help a data scientist with data cleaning and from going too far down the wrong path. It can also inform what true outliers are and which values might just be due to measurement error.&lt;/p&gt;

&lt;p&gt;Often the most challenging part of building a machine learning model is feature engineering. Understanding variables and how they relate to an outcome is extremely important for this. Knowing the domain can help direct the data exploration and greatly speed (and enhance) the feature engineering process.&lt;/p&gt;

&lt;p&gt;Once features are generated, knowing what relationships between variables are plausible help for basic sanity checks. Being able to glance at the outcome of a model and determine if they make sense goes a long way for quality assurance of any analytical work.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Finally, one of the biggest reasons a strong understanding of the data is important is because you have to interpret the results of analyses and modeling work.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Knowing what results are important and which are trivial is important for the presentation and communication of results. It’s also important to know what results are actionable.&lt;/p&gt;

&lt;h2 id=&quot;process-tofollow&quot;&gt;Process to follow&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*TPtwP0mAlx6JGjSiJCy18g.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;problem-definition&quot;&gt;Problem Definition&lt;/h3&gt;

&lt;p&gt;The first thing you have to do before you solve a problem is to define exactly what it is. You need to be able to translate data questions into something actionable.&lt;/p&gt;

&lt;p&gt;You’ll often get ambiguous inputs from the people who have problems. You’ll have to develop the intuition to turn scarce inputs into actionable outputs–and to ask the questions that nobody else is asking.&lt;/p&gt;

&lt;h3 id=&quot;data-collection&quot;&gt;Data Collection&lt;/h3&gt;

&lt;p&gt;Once you’ve defined the problem, you’ll need data to give you the insights needed to turn the problem around with a solution. This part of the process involves thinking through what data you’ll need and finding ways to get that data, whether it’s querying internal databases, or purchasing external data-sets.&lt;/p&gt;

&lt;h3 id=&quot;data-understanding&quot;&gt;Data Understanding&lt;/h3&gt;

&lt;p&gt;The difficulty here isn’t coming up with ideas to test, it’s coming up with ideas that are likely to turn into insights. You’ll have a fixed deadline for your AI project, so you’ll have to prioritize your questions.&lt;/p&gt;

&lt;p&gt;You’ll have to look at some of the most interesting patterns that can help explain why sales are reduced for this group. You might notice that they don’t tend to be very active on social media, with few of them having Twitter or Facebook accounts. You might also notice that most of them are older than your general audience. From that you can begin to trace patterns you can analyze more deeply.&lt;/p&gt;

&lt;h3 id=&quot;feature-engineering&quot;&gt;Feature Engineering&lt;/h3&gt;

&lt;p&gt;Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. If feature engineering is done correctly, it increases the predictive power of machine learning algorithms by creating features from raw data that help facilitate the machine learning process. Feature Engineering is, in fact, an art.&lt;/p&gt;

&lt;h3 id=&quot;modelling&quot;&gt;Modelling&lt;/h3&gt;

&lt;p&gt;Depending on the type of question that you’re trying to answer, there are many modelling algorithms available. You run the selected algorithm/s on the training data to build the models.&lt;/p&gt;

&lt;h3 id=&quot;validation&quot;&gt;Validation&lt;/h3&gt;

&lt;p&gt;Validation is a step used to evaluate the trained model on validation data. You use a series of competing for machine-learning algorithms along with the various associated tuning parameters that are geared toward answering the question of interest with the current data.&lt;/p&gt;

&lt;h3 id=&quot;tuning&quot;&gt;Tuning&lt;/h3&gt;

&lt;p&gt;Tuning an algorithm or machine learning technique can be simply thought of as a process which one goes through in which they optimize the parameters that impact the model in order to enable the algorithm to perform the best.&lt;/p&gt;

&lt;h3 id=&quot;deployment&quot;&gt;Deployment&lt;/h3&gt;

&lt;p&gt;After you have a set of models that perform well, you can operationalize them for other applications to consume. Depending on the business requirements, predictions are made either in real-time or on a batch basis. To deploy models, you expose them with an open API interface. The interface enables the model to be easily consumed from various applications.&lt;/p&gt;

&lt;h2 id=&quot;tools-tomaster&quot;&gt;Tools to master&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*Y0AVQ5pq0t0NKEec9AXxZQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The list mentioned here is not exhaustive, it depends more on what kind of problem you are solving and in what tech stack you are working.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;sql&quot;&gt;SQL&lt;/h3&gt;

&lt;p&gt;Structured Query Language (SQL) is a standard computer language for relational database management and data manipulation. SQL is used to query, insert, update and modify data. Most relational databases support SQL.&lt;/p&gt;

&lt;p&gt;As data collection has increased exponentially, so has the need for people skilled at using and interacting with data; to be able to think critically, and provide insights to make better decisions and optimize their businesses. The skills necessary to be a good data scientist include being able to retrieve and work with data and to do that you need to be well versed in SQL, the standard language for communicating with database systems.&lt;/p&gt;

&lt;h3 id=&quot;r&quot;&gt;R&lt;/h3&gt;

&lt;p&gt;R is a programming language and software environment for statistical analysis, graphics representation and reporting. In the world of AI, R is an increasingly popular language for a reason. It was built with statistical manipulation in mind, and there’s an incredible ecosystem of packages for R that let you do amazing things — particularly in data visualization.&lt;/p&gt;

&lt;h3 id=&quot;python&quot;&gt;Python&lt;/h3&gt;

&lt;p&gt;Python is a general-purpose interpreted, interactive, object-oriented, and high-level programming language. Python is no-doubt the best-suited language for a Data Scientist. It is a free, flexible and powerful open-source language. Python cuts development time in half with its simple and easy to read syntax. With Python, you can perform data manipulation, analysis, and visualization. Python provides powerful libraries for Machine learning applications and other scientific computations.&lt;/p&gt;

&lt;h3 id=&quot;tensorflow&quot;&gt;Tensorflow&lt;/h3&gt;

&lt;p&gt;Currently, the most famous deep learning library in the world is Google’s TensorFlow. Google product uses machine learning in all of its products to improve the search engine, translation, image captioning or recommendations.&lt;/p&gt;

&lt;p&gt;TensorFlow is the best library of all because it is built to be accessible to everyone. Tensorflow library incorporates different API to built at scale deep learning architecture like CNN or RNN. TensorFlow is based on graph computation; it allows the developer to visualize the construction of the neural network with Tensorboad. This tool is helpful to debug the program. Finally, Tensorflow is built to be deployed at scale. It runs on CPU and GPU.&lt;/p&gt;

&lt;h3 id=&quot;keras&quot;&gt;Keras&lt;/h3&gt;

&lt;p&gt;Keras is a high-level neural networks API, capable of running on top of Tensorflow, Theano, and CNTK. It enables fast experimentation through a high level, user-friendly, modular and extensible API.&lt;/p&gt;

&lt;p&gt;Keras allows for easy and fast prototyping (through user-friendliness, modularity, and extensibility). It supports both convolutional networks and recurrent networks, as well as combinations of the two. It runs seamlessly on CPU and GPU.&lt;/p&gt;

&lt;p&gt;So this is all that I needed to cover in this article. Now you know what concepts you need to learn, the process you need to follow and the tools you need to master in order to get proficient in the field of AI.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Title: Building Blocks of Artificial Intelligence Date: 2019-12-27 17:10 Author: ankitrathi Category: Uncategorized Tags: Artificial Intelligence, Building Blocks, Data Science, Machine Learning, Towards Data Science Slug: building-blocks-of-artificial-intelligence Status: published There are a few core skills in every job. To perform that job, you need to be aware of core concepts, you need to be aware of the end to end process and you need to learn how to use related tools to perform that job. Artificial Intelligence is no different, it has its own core concepts, processes and tools. This post covers the core concepts you need to learn, the end-to-end process you need to be aware of &amp;amp; important tools you need to master to work as a data scientist. Please note that this post only outlines the concepts, processes and tools used by data scientists. I will publish the resources (mostly free) for these topics in upcoming post. Concepts to learn Mathematics Artificial Intelligence contains math — no avoiding that! This section is for learners about basic math they need in order to be successful in almost any AI project/problem. So let’s start: Multivariate Calculus Calculus is a set of tools for analyzing the relationship between functions and their inputs. In Multivariate Calculus, we can take a function with multiple inputs and determine the influence of each of them separately. In AI, we try to find the inputs which enable a function to best match the data. The slope or descent describes the rate of change off the output with respect to an input. Determining the influence of each input on the output is also one of the critical tasks. All this requires a solid understanding of Multivariate Calculus. Linear Algebra The word algebra comes from the Arabi word “al-jabr” which means “the reunion of broken parts”. This is the collection of methods deriving unknowns from knowns in mathematics. Linear Algebra is the branch that deals with linear equations and linear functions which are represented through matrices and vectors. In simpler words, it helps us understand geometric terms such as planes, in higher dimensions, and perform mathematical operations on them. By definition, algebra deals primarily with scalars (one-dimensional entities), but Linear Algebra has vectors and matrices (entities which possess two or more dimensional components) to deal with linear equations and functions. Linear Algebra is central to almost all areas of mathematics like geometry and functional analysis. Its concepts are a crucial prerequisite for understanding the theory behind AI. You don’t need to understand Linear Algebra before getting started in AI, but at some point, you may want to gain a better understanding of how the different algorithms really work under the hood. So if you really want to be a professional in this field, you will have to master the parts of Linear Algebra that are important for AI. Statistics &amp;amp; Probability Statistics is a mathematical body of science that pertains to the collection, analysis, interpretation or explanation, and presentation of data. Probability is the chance that something will happen — how likely it is that some event will happen. Statistics help you to understand your data and is an initial &amp;amp; very important step of AI. This is due to the fact that AI is all about making predictions and you can’t predict if you can’t understand the patterns in existing data. Uncertainty and randomness occur in many aspects of our daily life and having a good knowledge of probability helps us make sense of these uncertainties. Learning about probability helps us make informed judgments on what is likely to happen, based on a pattern of data collected previously or an estimate. AI often uses statistical inferences to predict or analyze trends from data, while statistical inferences use probability distributions of data. Hence knowing probability &amp;amp; statistics and its applications are important to work effectively on AI problems. Programming To execute the AI pipeline, you need to learn algorithm design as well as fundamental programming concepts such as data selection, iteration and functional decomposition, data abstraction and organisation. In addition to this, you need to learn how to perform simple data visualizations using programming and embed your learning using problem-based assignments. Machine Learning Algorithms Machine learning algorithms can be divided into 3 broad categories — Supervised learning, Unsupervised learning Reinforcement learning. Supervised learning is useful in cases where a property (label) is available for a certain dataset (training set) but is missing and needs to be predicted for other instances. Unsupervised learning is useful in cases where the challenge is to discover implicit relationships in a given unlabeled dataset (items are not pre-assigned). Reinforcement learning falls between these 2 extremes — there is some form of feedback available for each predictive step or action, but no precise label or error message. Intrinsic details of various algorithms is not in scope of this series, you can refer the resources mentioned in the next post to learn them. Supervised learning can be further divided into Regression (Linear, Non-linear, etc) &amp;amp; Classification (Logistics Regression, Decision Tree, Naïve Bayes etc) algorithms. Some algorithms can be used for regression as well as classification i.e. Random Forests, Support Vector Machines, etc. Unsupervised learning can also be further divided into Clustering, Anomaly Detection, Associative Mining. Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward. Deep Learning Frameworks Deep learning frameworks are a more advanced form of ML and solve specific problems where data is either unstructured or huge or both. Neural Nets, CNNs, RNNs &amp;amp; LSTM, GANs are the frameworks one needs to be aware of. Domain Knowledge This lack of domain knowledge, while perfectly understandable, can be a major barrier to data scientists. For one thing, it’s difficult to come up with project ideas in a domain that you don’t know much about. It can also be difficult to determine the type of data that may be helpful for a project — if you want to build a model to predict an outcome, you need to know what types of variables might be related to this outcome so you can make sure to gather the right data. Knowing the domain is useful not only for figuring out projects and how to approach them but also for having rules of thumb for sanity checks on the data. Knowing how data is captured (is it hand-entered? Is it from machines that can give false readings for any number of reasons?) can help a data scientist with data cleaning and from going too far down the wrong path. It can also inform what true outliers are and which values might just be due to measurement error. Often the most challenging part of building a machine learning model is feature engineering. Understanding variables and how they relate to an outcome is extremely important for this. Knowing the domain can help direct the data exploration and greatly speed (and enhance) the feature engineering process. Once features are generated, knowing what relationships between variables are plausible help for basic sanity checks. Being able to glance at the outcome of a model and determine if they make sense goes a long way for quality assurance of any analytical work. Finally, one of the biggest reasons a strong understanding of the data is important is because you have to interpret the results of analyses and modeling work. Knowing what results are important and which are trivial is important for the presentation and communication of results. It’s also important to know what results are actionable. Process to follow Problem Definition The first thing you have to do before you solve a problem is to define exactly what it is. You need to be able to translate data questions into something actionable. You’ll often get ambiguous inputs from the people who have problems. You’ll have to develop the intuition to turn scarce inputs into actionable outputs–and to ask the questions that nobody else is asking. Data Collection Once you’ve defined the problem, you’ll need data to give you the insights needed to turn the problem around with a solution. This part of the process involves thinking through what data you’ll need and finding ways to get that data, whether it’s querying internal databases, or purchasing external data-sets. Data Understanding The difficulty here isn’t coming up with ideas to test, it’s coming up with ideas that are likely to turn into insights. You’ll have a fixed deadline for your AI project, so you’ll have to prioritize your questions. You’ll have to look at some of the most interesting patterns that can help explain why sales are reduced for this group. You might notice that they don’t tend to be very active on social media, with few of them having Twitter or Facebook accounts. You might also notice that most of them are older than your general audience. From that you can begin to trace patterns you can analyze more deeply. Feature Engineering Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. If feature engineering is done correctly, it increases the predictive power of machine learning algorithms by creating features from raw data that help facilitate the machine learning process. Feature Engineering is, in fact, an art. Modelling Depending on the type of question that you’re trying to answer, there are many modelling algorithms available. You run the selected algorithm/s on the training data to build the models. Validation Validation is a step used to evaluate the trained model on validation data. You use a series of competing for machine-learning algorithms along with the various associated tuning parameters that are geared toward answering the question of interest with the current data. Tuning Tuning an algorithm or machine learning technique can be simply thought of as a process which one goes through in which they optimize the parameters that impact the model in order to enable the algorithm to perform the best. Deployment After you have a set of models that perform well, you can operationalize them for other applications to consume. Depending on the business requirements, predictions are made either in real-time or on a batch basis. To deploy models, you expose them with an open API interface. The interface enables the model to be easily consumed from various applications. Tools to master The list mentioned here is not exhaustive, it depends more on what kind of problem you are solving and in what tech stack you are working. SQL Structured Query Language (SQL) is a standard computer language for relational database management and data manipulation. SQL is used to query, insert, update and modify data. Most relational databases support SQL. As data collection has increased exponentially, so has the need for people skilled at using and interacting with data; to be able to think critically, and provide insights to make better decisions and optimize their businesses. The skills necessary to be a good data scientist include being able to retrieve and work with data and to do that you need to be well versed in SQL, the standard language for communicating with database systems. R R is a programming language and software environment for statistical analysis, graphics representation and reporting. In the world of AI, R is an increasingly popular language for a reason. It was built with statistical manipulation in mind, and there’s an incredible ecosystem of packages for R that let you do amazing things — particularly in data visualization. Python Python is a general-purpose interpreted, interactive, object-oriented, and high-level programming language. Python is no-doubt the best-suited language for a Data Scientist. It is a free, flexible and powerful open-source language. Python cuts development time in half with its simple and easy to read syntax. With Python, you can perform data manipulation, analysis, and visualization. Python provides powerful libraries for Machine learning applications and other scientific computations. Tensorflow Currently, the most famous deep learning library in the world is Google’s TensorFlow. Google product uses machine learning in all of its products to improve the search engine, translation, image captioning or recommendations. TensorFlow is the best library of all because it is built to be accessible to everyone. Tensorflow library incorporates different API to built at scale deep learning architecture like CNN or RNN. TensorFlow is based on graph computation; it allows the developer to visualize the construction of the neural network with Tensorboad. This tool is helpful to debug the program. Finally, Tensorflow is built to be deployed at scale. It runs on CPU and GPU. Keras Keras is a high-level neural networks API, capable of running on top of Tensorflow, Theano, and CNTK. It enables fast experimentation through a high level, user-friendly, modular and extensible API. Keras allows for easy and fast prototyping (through user-friendliness, modularity, and extensibility). It supports both convolutional networks and recurrent networks, as well as combinations of the two. It runs seamlessly on CPU and GPU. So this is all that I needed to cover in this article. Now you know what concepts you need to learn, the process you need to follow and the tools you need to master in order to get proficient in the field of AI. Ankit Rathi is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture. Why don’t you connect with Ankit on Twitter, LinkedIn or Instagram?</summary></entry><entry><title type="html">How to Navigate Artificial Intelligence Landscape?</title><link href="https://ankit-rathi.github.io/data-and-ai/markdown/2019/12/07/how-to-navigate-artificial-intelligence-landscape.html" rel="alternate" type="text/html" title="How to Navigate Artificial Intelligence Landscape?" /><published>2019-12-07T00:00:00-06:00</published><updated>2019-12-07T00:00:00-06:00</updated><id>https://ankit-rathi.github.io/data-and-ai/markdown/2019/12/07/how-to-navigate-artificial-intelligence-landscape</id><content type="html" xml:base="https://ankit-rathi.github.io/data-and-ai/markdown/2019/12/07/how-to-navigate-artificial-intelligence-landscape.html">&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1200/0*QNdQhs_T3ffa6B0m.jpeg&quot; alt=&quot;Photo by [Rob Bates](https://unsplash.com/photos/0eLg8OTuCw0?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/landscape?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText)&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Want to learn more? visit &lt;a href=&quot;http://www.ankitrathi.com&quot;&gt;www.ankitrathi.com&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Artificial Intelligence (AI) is a complex and evolving field. The first challenge an AI aspirant faces is understanding the landscape and how he could navigate through it. Consider this, if you are travelling to a new city, and if you don’t have the map, you will have trouble to navigate the city and you will need to ask a lot of random people during your travel without knowing how much they know about the place. Similarly, all the newcomers to AI have this trouble, and there are two ways to deal with this, arrange the map (or a guide) or travel yourself and learn with experience.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Note: AI &amp;amp; DS/AI terms are used interchangeably in the article where DS means Data Science.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/0*QJbUB6csfF0SznF0.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;This post intends to serve as a map of Artificial Intelligence field.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You might have heard data science, machine learning, deep learning, artificial intelligence etc terminology but might not be fully aware of these terms, what to use when and how these topics are interconnected. After going through this post, you should be able to understand what is where in the AI field.&lt;/p&gt;

&lt;h2 id=&quot;multi-disciplinary-field&quot;&gt;Multi-disciplinary field&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;AI is a multidisciplinary field with sub-fields of study in Math/Statistics, CS/IT &amp;amp; Business/Domain knowledge.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Math/Statistics is required to understand the data and relationship between data elements. CS/IT skills are required to process the data to generate insights. And Business or domain knowledge is required to apply above to skills in the context of a business problem.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/0*VR8Sy8nm4EcQKn_6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;computer-scienceit&quot;&gt;Computer Science/IT&lt;/h2&gt;

&lt;p&gt;Programming is an essential skill to become a data scientist but one needs not be a hard-core programmer to learn AI. Having familiarity with basic concepts of programming will ease the process of learning AI programming tools like Python/R. These basic concepts of programming should help a candidate get a long way on the journey to pursue a career in AI as it is all about writing efficient code to analyse big data and not being a master of programming. Individuals should learn the basics of programming in Python/R (or any relevant language) before they begin to work on AI problems/projects.&lt;/p&gt;

&lt;h2 id=&quot;maths--statistics&quot;&gt;Maths &amp;amp; Statistics&lt;/h2&gt;

&lt;p&gt;AI teams have people from diverse backgrounds like chemical engineering, physics, economics, statistics, mathematics, operations research, computer science, etc. You will find many data scientists with a bachelor’s degree in statistics and machine learning but it is not a requirement to learn AI. However, having familiarity with the basic concepts of Math and Statistics like Linear Algebra, Calculus, Probability, etc. is important to learn AI.&lt;/p&gt;

&lt;h2 id=&quot;domainbusiness-knowledge&quot;&gt;Domain/Business Knowledge&lt;/h2&gt;

&lt;p&gt;Subsequently, the business knowledge that the data scientists would need to have would be related to the domain that the project/analysis is in. For instance, if the data scientist is working for a credit card department in a bank, it will need to understand the specific business definitions, regulations, accounting policies &amp;amp; international standards, processes etc. This is the part that is more specific to the organization the data scientist is deployed in.&lt;/p&gt;

&lt;p&gt;In my view, one thing to take care while the hiring data scientists is not to give huge preference to domain knowledge. This may severely limit the supply of AI talents to the organization. You would have a better chance of getting more value from AI by looking for those that are strong in math &amp;amp; programming, being able to convert business objectives to mathematical models. Based on my observation, this is a much more difficult skill to find or train, as compared to domain knowledge.&lt;/p&gt;

&lt;h2 id=&quot;various-terminologies&quot;&gt;Various Terminologies&lt;/h2&gt;

&lt;p&gt;As an AI starter, you will come across many similar terminologies. First thing you need to do is to understand what each term means and where each fits in the bigger picture. Data Science, Business Intelligence, Data Mining, Machine Learning, Deep Learning, Artificial Intelligence; let’s have a look at &lt;em&gt;Wikipedia&lt;/em&gt; definition for each term &amp;amp; later see how these are interconnected.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/0*j4Nh1WD1U0RZQCWy.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;data-science&quot;&gt;Data Science&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from data in various forms, both structured and unstructured, like data mining.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;business-intelligence&quot;&gt;Business Intelligence&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Business intelligence comprises the strategies and technologies used by enterprises for the data analysis of business information. BI technologies provide historical, current and predictive views of business operations.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;data-mining&quot;&gt;Data Mining&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Data mining is the process of discovering patterns in large data sets involving methods at the intersection of machine learning, statistics, and database systems.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;machine-learning&quot;&gt;Machine Learning&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Machine learning is the scientific study of algorithms and statistical models that computer systems use to progressively improve their performance on a specific task.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;deep-learning&quot;&gt;Deep Learning&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Deep learning is part of a broader family of machine learning methods based on learning data representations, as opposed to task-specific algorithms.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;artificial-intelligence&quot;&gt;Artificial Intelligence&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Artificial intelligence, sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and other animals.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;interconnection&quot;&gt;Interconnection&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/0*2oYhsUxmRbGSgZ_i.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Data mining uses statistics and other programming languages to find hidden patterns in the data to explain a certain phenomenon. It helps in building a perception about the data using both math and programming.&lt;/p&gt;

&lt;p&gt;Machine Learning deploys data mining techniques as well as other algorithms to develop models of what is happening behind some data to forecast future outcomes.&lt;/p&gt;

&lt;p&gt;Artificial Intelligence uses models developed by Machine Learning and other algorithms to lead to intelligent behaviour. AI is very much programming based.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Data Mining demonstrates patterns&lt;/li&gt;
  &lt;li&gt;Machine Learning forecasts with models&lt;/li&gt;
  &lt;li&gt;Artificial Intelligence shapes behaviours&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;So you see that these terms are different but still inter-connected.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;roles-in-artificial-intelligence&quot;&gt;Roles in Artificial Intelligence&lt;/h2&gt;

&lt;p&gt;Before looking into the skill-set of a data scientist, let’s have a look at various roles required to work and deliver a AI project, after all, it’s a teamwork.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Every role has its own skills that are critical to AI projects at various stages.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/0*zGdwTKLtbyzDuKJP.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;data-scientist&quot;&gt;Data Scientist&lt;/h2&gt;

&lt;p&gt;A data scientist is someone who knows how to extract meaning from and interpret data, which requires both tools and methods from statistics and machine learning. She spends a lot of time in the process of collecting, cleaning, and munging data. Domain knowledge is also an integral part of the skill.&lt;/p&gt;

&lt;h3 id=&quot;machine-learningai-engineer&quot;&gt;Machine Learning/AI Engineer&lt;/h3&gt;

&lt;p&gt;Machine learning/AI engineers are sophisticated programmers who develop machines and systems that can learn and apply knowledge without specific domain requirement.&lt;/p&gt;

&lt;h3 id=&quot;data-analyst&quot;&gt;Data Analyst&lt;/h3&gt;

&lt;p&gt;Data analysts translate numbers into plain English. Every business collects data, whether it’s sales figures, market research, logistics, or transportation costs. A data analyst’s job is to take that data and use it to help companies make better business decisions. There are many different types of data analysts in the field, including operations analysts, marketing analysts, financial analysts, etc.&lt;/p&gt;

&lt;h3 id=&quot;data-engineer&quot;&gt;Data Engineer&lt;/h3&gt;

&lt;p&gt;Data Engineers are responsible for the creation and maintenance of analytics infrastructure that enables almost every other function in the data world. They are responsible for the development, construction, maintenance and testing of architectures, such as databases and large-scale processing systems.&lt;/p&gt;

&lt;h3 id=&quot;data-architect&quot;&gt;Data Architect&lt;/h3&gt;

&lt;p&gt;Data architects build complex computer database systems for companies, either for the general public or for individual companies. They work with a team that looks at the needs of the database, the data that is available and creates a blueprint for creating, testing and maintaining that data architecture.&lt;/p&gt;

&lt;h3 id=&quot;analytics-manager&quot;&gt;Analytics Manager&lt;/h3&gt;

&lt;p&gt;The analytics manager coordinates the different tasks that must be completed by their team for an AI project. Tasks may include researching and creating effective methods to collect data, analyzing information, and recommending solutions to business.&lt;/p&gt;

&lt;h3 id=&quot;business-analyst&quot;&gt;Business Analyst&lt;/h3&gt;

&lt;p&gt;AI business analyst converts the business problem statement to an AI problem statement which means what data needs to be analyzed to arrive at the insights. The data would then be reviewed with the technology team and results would be delivered to the business team in the form of insights and data patterns. The business analyst should also be knowledgeable enough to apply various predictive modelling techniques and right model selection for generating insights for the problem at hand.&lt;/p&gt;

&lt;h3 id=&quot;quality-analyst&quot;&gt;Quality Analyst&lt;/h3&gt;

&lt;p&gt;The job of quality analyst includes checking the quality of the training data-set, preparing data-sets for testing, running statistics on human-labelled data-sets, evaluating precision and recall on the resulting ML model, reporting on unexpected patterns in outputs, and implementing necessary tools to automate repetitive parts of the work. Experience in software testing with data quality or DS/ML focus, understanding of statistics, exposure to AI / Machine Learning techniques and coding proficiency in Python, are some of the skills required for the job.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;To work on AI projects in any of the above mentioned roles, one needs to have an understanding of the core concepts at a high level but depth is required in the specific area you would be working in.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;academia-vsindustry&quot;&gt;Academia Vs Industry&lt;/h2&gt;

&lt;p&gt;Academia and Industry are different fields with different people and culture. People working in Academia for longer tenure may find it difficult to adjust to industry culture and vice versa.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;There is also an academic trap when your career trajectory is so specialized for academia that you’re unprepared for a job outside of it.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The academic trap happens in all areas of study, but for this post, we focus only on AI students who want to leave academia for AI positions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/0*JcUnrkHu2ns0P2ug.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Further, companies are often hesitant to hire people coming straight from academia for various reasons like:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In academia, individuals prefer writing papers over internships, making grants over learning programming languages, and not doing the things that could help you in the industry but not academia. The things that are important for academic hirings, such as papers, talks, and grants, are not as important in the industry.&lt;/li&gt;
  &lt;li&gt;Working as a data scientist within a corporation requires an understanding of how the business world works, including how quickly deliverable need to be made, how to craft a good presentation, and how to word an email to make a request.&lt;/li&gt;
  &lt;li&gt;In academia, you are encouraged to find the most innovative and elegant solution. In industry, you are encouraged to spend as little time as possible to find an analytical solution that just fits the need.&lt;/li&gt;
  &lt;li&gt;Salary expectations for advanced degree holders are higher than someone with only an undergraduate degree. This also pushes away recruiters as the industry works in a different way, culture is simply different than the academic one. People coming from academia need to learn these lessons at their first job, which means that there is a lot of risk for the hiring company.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ankitrathi.com/&quot;&gt;&lt;em&gt;Ankit Rathi&lt;/em&gt;&lt;/a&gt; &lt;em&gt;is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why don’t you connect with Ankit on&lt;/em&gt; &lt;a href=&quot;https://twitter.com/rathiankit&quot;&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; &lt;a href=&quot;https://www.linkedin.com/in/ankitrathi/&quot;&gt;&lt;em&gt;LinkedIn&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or&lt;/em&gt; &lt;a href=&quot;https://instagram.com/ankitrathi/&quot;&gt;&lt;em&gt;Instagram&lt;/em&gt;&lt;/a&gt;&lt;em&gt;?&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Want to learn more? visit www.ankitrathi.com Artificial Intelligence (AI) is a complex and evolving field. The first challenge an AI aspirant faces is understanding the landscape and how he could navigate through it. Consider this, if you are travelling to a new city, and if you don’t have the map, you will have trouble to navigate the city and you will need to ask a lot of random people during your travel without knowing how much they know about the place. Similarly, all the newcomers to AI have this trouble, and there are two ways to deal with this, arrange the map (or a guide) or travel yourself and learn with experience. Note: AI &amp;amp; DS/AI terms are used interchangeably in the article where DS means Data Science. This post intends to serve as a map of Artificial Intelligence field. You might have heard data science, machine learning, deep learning, artificial intelligence etc terminology but might not be fully aware of these terms, what to use when and how these topics are interconnected. After going through this post, you should be able to understand what is where in the AI field. Multi-disciplinary field AI is a multidisciplinary field with sub-fields of study in Math/Statistics, CS/IT &amp;amp; Business/Domain knowledge. Math/Statistics is required to understand the data and relationship between data elements. CS/IT skills are required to process the data to generate insights. And Business or domain knowledge is required to apply above to skills in the context of a business problem. Computer Science/IT Programming is an essential skill to become a data scientist but one needs not be a hard-core programmer to learn AI. Having familiarity with basic concepts of programming will ease the process of learning AI programming tools like Python/R. These basic concepts of programming should help a candidate get a long way on the journey to pursue a career in AI as it is all about writing efficient code to analyse big data and not being a master of programming. Individuals should learn the basics of programming in Python/R (or any relevant language) before they begin to work on AI problems/projects. Maths &amp;amp; Statistics AI teams have people from diverse backgrounds like chemical engineering, physics, economics, statistics, mathematics, operations research, computer science, etc. You will find many data scientists with a bachelor’s degree in statistics and machine learning but it is not a requirement to learn AI. However, having familiarity with the basic concepts of Math and Statistics like Linear Algebra, Calculus, Probability, etc. is important to learn AI. Domain/Business Knowledge Subsequently, the business knowledge that the data scientists would need to have would be related to the domain that the project/analysis is in. For instance, if the data scientist is working for a credit card department in a bank, it will need to understand the specific business definitions, regulations, accounting policies &amp;amp; international standards, processes etc. This is the part that is more specific to the organization the data scientist is deployed in. In my view, one thing to take care while the hiring data scientists is not to give huge preference to domain knowledge. This may severely limit the supply of AI talents to the organization. You would have a better chance of getting more value from AI by looking for those that are strong in math &amp;amp; programming, being able to convert business objectives to mathematical models. Based on my observation, this is a much more difficult skill to find or train, as compared to domain knowledge. Various Terminologies As an AI starter, you will come across many similar terminologies. First thing you need to do is to understand what each term means and where each fits in the bigger picture. Data Science, Business Intelligence, Data Mining, Machine Learning, Deep Learning, Artificial Intelligence; let’s have a look at Wikipedia definition for each term &amp;amp; later see how these are interconnected. Data Science Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from data in various forms, both structured and unstructured, like data mining. Business Intelligence Business intelligence comprises the strategies and technologies used by enterprises for the data analysis of business information. BI technologies provide historical, current and predictive views of business operations. Data Mining Data mining is the process of discovering patterns in large data sets involving methods at the intersection of machine learning, statistics, and database systems. Machine Learning Machine learning is the scientific study of algorithms and statistical models that computer systems use to progressively improve their performance on a specific task. Deep Learning Deep learning is part of a broader family of machine learning methods based on learning data representations, as opposed to task-specific algorithms. Artificial Intelligence Artificial intelligence, sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and other animals. Interconnection Data mining uses statistics and other programming languages to find hidden patterns in the data to explain a certain phenomenon. It helps in building a perception about the data using both math and programming. Machine Learning deploys data mining techniques as well as other algorithms to develop models of what is happening behind some data to forecast future outcomes. Artificial Intelligence uses models developed by Machine Learning and other algorithms to lead to intelligent behaviour. AI is very much programming based. Data Mining demonstrates patterns Machine Learning forecasts with models Artificial Intelligence shapes behaviours So you see that these terms are different but still inter-connected. Roles in Artificial Intelligence Before looking into the skill-set of a data scientist, let’s have a look at various roles required to work and deliver a AI project, after all, it’s a teamwork. Every role has its own skills that are critical to AI projects at various stages. Data Scientist A data scientist is someone who knows how to extract meaning from and interpret data, which requires both tools and methods from statistics and machine learning. She spends a lot of time in the process of collecting, cleaning, and munging data. Domain knowledge is also an integral part of the skill. Machine Learning/AI Engineer Machine learning/AI engineers are sophisticated programmers who develop machines and systems that can learn and apply knowledge without specific domain requirement. Data Analyst Data analysts translate numbers into plain English. Every business collects data, whether it’s sales figures, market research, logistics, or transportation costs. A data analyst’s job is to take that data and use it to help companies make better business decisions. There are many different types of data analysts in the field, including operations analysts, marketing analysts, financial analysts, etc. Data Engineer Data Engineers are responsible for the creation and maintenance of analytics infrastructure that enables almost every other function in the data world. They are responsible for the development, construction, maintenance and testing of architectures, such as databases and large-scale processing systems. Data Architect Data architects build complex computer database systems for companies, either for the general public or for individual companies. They work with a team that looks at the needs of the database, the data that is available and creates a blueprint for creating, testing and maintaining that data architecture. Analytics Manager The analytics manager coordinates the different tasks that must be completed by their team for an AI project. Tasks may include researching and creating effective methods to collect data, analyzing information, and recommending solutions to business. Business Analyst AI business analyst converts the business problem statement to an AI problem statement which means what data needs to be analyzed to arrive at the insights. The data would then be reviewed with the technology team and results would be delivered to the business team in the form of insights and data patterns. The business analyst should also be knowledgeable enough to apply various predictive modelling techniques and right model selection for generating insights for the problem at hand. Quality Analyst The job of quality analyst includes checking the quality of the training data-set, preparing data-sets for testing, running statistics on human-labelled data-sets, evaluating precision and recall on the resulting ML model, reporting on unexpected patterns in outputs, and implementing necessary tools to automate repetitive parts of the work. Experience in software testing with data quality or DS/ML focus, understanding of statistics, exposure to AI / Machine Learning techniques and coding proficiency in Python, are some of the skills required for the job. To work on AI projects in any of the above mentioned roles, one needs to have an understanding of the core concepts at a high level but depth is required in the specific area you would be working in. Academia Vs Industry Academia and Industry are different fields with different people and culture. People working in Academia for longer tenure may find it difficult to adjust to industry culture and vice versa. There is also an academic trap when your career trajectory is so specialized for academia that you’re unprepared for a job outside of it. The academic trap happens in all areas of study, but for this post, we focus only on AI students who want to leave academia for AI positions. Further, companies are often hesitant to hire people coming straight from academia for various reasons like: In academia, individuals prefer writing papers over internships, making grants over learning programming languages, and not doing the things that could help you in the industry but not academia. The things that are important for academic hirings, such as papers, talks, and grants, are not as important in the industry. Working as a data scientist within a corporation requires an understanding of how the business world works, including how quickly deliverable need to be made, how to craft a good presentation, and how to word an email to make a request. In academia, you are encouraged to find the most innovative and elegant solution. In industry, you are encouraged to spend as little time as possible to find an analytical solution that just fits the need. Salary expectations for advanced degree holders are higher than someone with only an undergraduate degree. This also pushes away recruiters as the industry works in a different way, culture is simply different than the academic one. People coming from academia need to learn these lessons at their first job, which means that there is a lot of risk for the hiring company. Ankit Rathi is an AI architect, published author &amp;amp; well-known speaker. His interest lies primarily in building end-to-end AI applications/products following best practices of Data Engineering and Architecture. Why don’t you connect with Ankit on Twitter, LinkedIn or Instagram?</summary></entry></feed>